
Train 12467, Val 496, Test 1153
TOTAL TRAINABLE PARAMETERS : 97319
RATIOS: Temporal  88.5% , Classifier  11.5%
EPOCH 1/2
Step [100/12467], Loss: 1.7470, Acc : 45.42
Step [200/12467], Loss: 1.1983, Acc : 63.61
Step [300/12467], Loss: 0.9383, Acc : 71.18
Step [400/12467], Loss: 0.7912, Acc : 75.31
Step [500/12467], Loss: 0.6933, Acc : 78.06
Step [600/12467], Loss: 0.6232, Acc : 79.99
Step [700/12467], Loss: 0.5704, Acc : 81.48
Step [800/12467], Loss: 0.5288, Acc : 82.61
Step [900/12467], Loss: 0.4944, Acc : 83.60
Step [1000/12467], Loss: 0.4656, Acc : 84.44
Step [1100/12467], Loss: 0.4413, Acc : 85.12
Step [1200/12467], Loss: 0.4200, Acc : 85.71
Step [1300/12467], Loss: 0.4026, Acc : 86.19
Step [1400/12467], Loss: 0.3869, Acc : 86.64
Step [1500/12467], Loss: 0.3734, Acc : 87.03
Step [1600/12467], Loss: 0.3618, Acc : 87.37
Step [1700/12467], Loss: 0.3512, Acc : 87.68
Step [1800/12467], Loss: 0.3412, Acc : 87.96
Step [1900/12467], Loss: 0.3317, Acc : 88.23
Step [2000/12467], Loss: 0.3226, Acc : 88.50
Step [2100/12467], Loss: 0.3145, Acc : 88.73
Step [2200/12467], Loss: 0.3074, Acc : 88.95
Step [2300/12467], Loss: 0.3004, Acc : 89.16
Step [2400/12467], Loss: 0.2941, Acc : 89.33
Step [2500/12467], Loss: 0.2882, Acc : 89.52
Step [2600/12467], Loss: 0.2826, Acc : 89.69
Step [2700/12467], Loss: 0.2773, Acc : 89.85
Step [2800/12467], Loss: 0.2723, Acc : 90.00
Step [2900/12467], Loss: 0.2679, Acc : 90.14
Step [3000/12467], Loss: 0.2635, Acc : 90.27
Step [3100/12467], Loss: 0.2592, Acc : 90.40
Step [3200/12467], Loss: 0.2551, Acc : 90.53
Step [3300/12467], Loss: 0.2514, Acc : 90.64
Step [3400/12467], Loss: 0.2479, Acc : 90.76
Step [3500/12467], Loss: 0.2444, Acc : 90.85
Step [3600/12467], Loss: 0.2412, Acc : 90.95
Step [3700/12467], Loss: 0.2379, Acc : 91.05
Step [3800/12467], Loss: 0.2351, Acc : 91.15
Step [3900/12467], Loss: 0.2321, Acc : 91.24
Step [4000/12467], Loss: 0.2293, Acc : 91.32
Step [4100/12467], Loss: 0.2266, Acc : 91.41
Step [4200/12467], Loss: 0.2241, Acc : 91.48
Step [4300/12467], Loss: 0.2217, Acc : 91.55
Step [4400/12467], Loss: 0.2193, Acc : 91.63
Step [4500/12467], Loss: 0.2172, Acc : 91.69
Step [4600/12467], Loss: 0.2151, Acc : 91.76
Step [4700/12467], Loss: 0.2132, Acc : 91.82
Step [4800/12467], Loss: 0.2111, Acc : 91.88
Step [4900/12467], Loss: 0.2092, Acc : 91.94
Step [5000/12467], Loss: 0.2073, Acc : 92.00
Step [5100/12467], Loss: 0.2054, Acc : 92.06
Step [5200/12467], Loss: 0.2034, Acc : 92.12
Step [5300/12467], Loss: 0.2017, Acc : 92.17
Step [5400/12467], Loss: 0.1999, Acc : 92.23
Step [5500/12467], Loss: 0.1983, Acc : 92.28
Step [5600/12467], Loss: 0.1967, Acc : 92.33
Step [5700/12467], Loss: 0.1952, Acc : 92.38
Step [5800/12467], Loss: 0.1937, Acc : 92.43
Step [5900/12467], Loss: 0.1922, Acc : 92.48
Step [6000/12467], Loss: 0.1908, Acc : 92.52
Step [6100/12467], Loss: 0.1894, Acc : 92.57
Step [6200/12467], Loss: 0.1879, Acc : 92.62
Step [6300/12467], Loss: 0.1867, Acc : 92.65
Step [6400/12467], Loss: 0.1853, Acc : 92.70
Step [6500/12467], Loss: 0.1841, Acc : 92.74
Step [6600/12467], Loss: 0.1828, Acc : 92.78
Step [6700/12467], Loss: 0.1816, Acc : 92.82
Step [6800/12467], Loss: 0.1803, Acc : 92.86
Step [6900/12467], Loss: 0.1791, Acc : 92.90
Step [7000/12467], Loss: 0.1779, Acc : 92.94
Step [7100/12467], Loss: 0.1769, Acc : 92.97
Step [7200/12467], Loss: 0.1758, Acc : 93.00
Step [7300/12467], Loss: 0.1747, Acc : 93.04
Step [7400/12467], Loss: 0.1736, Acc : 93.07
Step [7500/12467], Loss: 0.1726, Acc : 93.11
Step [7600/12467], Loss: 0.1716, Acc : 93.13
Step [7700/12467], Loss: 0.1707, Acc : 93.17
Step [7800/12467], Loss: 0.1698, Acc : 93.20
Step [7900/12467], Loss: 0.1689, Acc : 93.23
Step [8000/12467], Loss: 0.1680, Acc : 93.25
Step [8100/12467], Loss: 0.1672, Acc : 93.28
Step [8200/12467], Loss: 0.1664, Acc : 93.31
Step [8300/12467], Loss: 0.1655, Acc : 93.34
Step [8400/12467], Loss: 0.1647, Acc : 93.37
Step [8500/12467], Loss: 0.1638, Acc : 93.40
Step [8600/12467], Loss: 0.1631, Acc : 93.42
Step [8700/12467], Loss: 0.1622, Acc : 93.45
Step [8800/12467], Loss: 0.1613, Acc : 93.48
Step [8900/12467], Loss: 0.1605, Acc : 93.51
Step [9000/12467], Loss: 0.1598, Acc : 93.53
Step [9100/12467], Loss: 0.1591, Acc : 93.56
Step [9200/12467], Loss: 0.1584, Acc : 93.58
Step [9300/12467], Loss: 0.1577, Acc : 93.61
Step [9400/12467], Loss: 0.1570, Acc : 93.63
Step [9500/12467], Loss: 0.1563, Acc : 93.66
Step [9600/12467], Loss: 0.1556, Acc : 93.68
Step [9700/12467], Loss: 0.1549, Acc : 93.70
Step [9800/12467], Loss: 0.1542, Acc : 93.72
Step [9900/12467], Loss: 0.1536, Acc : 93.75
Step [10000/12467], Loss: 0.1529, Acc : 93.77
Step [10100/12467], Loss: 0.1524, Acc : 93.78
Step [10200/12467], Loss: 0.1518, Acc : 93.80
Step [10300/12467], Loss: 0.1511, Acc : 93.83
Step [10400/12467], Loss: 0.1505, Acc : 93.84
Step [10500/12467], Loss: 0.1501, Acc : 93.86
Step [10600/12467], Loss: 0.1494, Acc : 93.88
Step [10700/12467], Loss: 0.1488, Acc : 93.90
Step [10800/12467], Loss: 0.1484, Acc : 93.92
Step [10900/12467], Loss: 0.1478, Acc : 93.93
Step [11000/12467], Loss: 0.1472, Acc : 93.96
Step [11100/12467], Loss: 0.1467, Acc : 93.97
Step [11200/12467], Loss: 0.1461, Acc : 93.99
Step [11300/12467], Loss: 0.1456, Acc : 94.01
Step [11400/12467], Loss: 0.1451, Acc : 94.03
Step [11500/12467], Loss: 0.1445, Acc : 94.04
Step [11600/12467], Loss: 0.1440, Acc : 94.06
Step [11700/12467], Loss: 0.1435, Acc : 94.08
Step [11800/12467], Loss: 0.1430, Acc : 94.10
Step [11900/12467], Loss: 0.1425, Acc : 94.12
Step [12000/12467], Loss: 0.1420, Acc : 94.13
Step [12100/12467], Loss: 0.1415, Acc : 94.15
Step [12200/12467], Loss: 0.1411, Acc : 94.16
Step [12300/12467], Loss: 0.1406, Acc : 94.18
Step [12400/12467], Loss: 0.1401, Acc : 94.19
Training time for 1 is 238.6341519355774
Validation . . .
Loss 0.1331,  Acc 95.44,  IoU 0.4787
Testing best epoch . . .
Loss 0.4459,  Acc 88.31,  IoU 0.4220
EPOCH 2/2
Step [100/12467], Loss: 0.0807, Acc : 96.07
Step [200/12467], Loss: 0.0829, Acc : 96.04
Step [300/12467], Loss: 0.0823, Acc : 96.05
Step [400/12467], Loss: 0.0804, Acc : 96.18
Step [500/12467], Loss: 0.0798, Acc : 96.19
Step [600/12467], Loss: 0.0799, Acc : 96.20
Step [700/12467], Loss: 0.0798, Acc : 96.19
Step [800/12467], Loss: 0.0797, Acc : 96.21
Step [900/12467], Loss: 0.0801, Acc : 96.19
Step [1000/12467], Loss: 0.0804, Acc : 96.16
Step [1100/12467], Loss: 0.0805, Acc : 96.14
Step [1200/12467], Loss: 0.0805, Acc : 96.16
Step [1300/12467], Loss: 0.0804, Acc : 96.17
Step [1400/12467], Loss: 0.0806, Acc : 96.17
Step [1500/12467], Loss: 0.0802, Acc : 96.19
Step [1600/12467], Loss: 0.0801, Acc : 96.19
Step [1700/12467], Loss: 0.0802, Acc : 96.20
Step [1800/12467], Loss: 0.0799, Acc : 96.22
Step [1900/12467], Loss: 0.0794, Acc : 96.23
Step [2000/12467], Loss: 0.0791, Acc : 96.24
Step [2100/12467], Loss: 0.0790, Acc : 96.26
Step [2200/12467], Loss: 0.0787, Acc : 96.27
Step [2300/12467], Loss: 0.0787, Acc : 96.26
Step [2400/12467], Loss: 0.0788, Acc : 96.26
Step [2500/12467], Loss: 0.0788, Acc : 96.25
Step [2600/12467], Loss: 0.0787, Acc : 96.26
Step [2700/12467], Loss: 0.0784, Acc : 96.27
Step [2800/12467], Loss: 0.0783, Acc : 96.28
Step [2900/12467], Loss: 0.0782, Acc : 96.27
Step [3000/12467], Loss: 0.0783, Acc : 96.27
Step [3100/12467], Loss: 0.0782, Acc : 96.28
Step [3200/12467], Loss: 0.0782, Acc : 96.28
Step [3300/12467], Loss: 0.0781, Acc : 96.28
Step [3400/12467], Loss: 0.0780, Acc : 96.29
Step [3500/12467], Loss: 0.0779, Acc : 96.30
Step [3600/12467], Loss: 0.0780, Acc : 96.30
Step [3700/12467], Loss: 0.0780, Acc : 96.30
Step [3800/12467], Loss: 0.0779, Acc : 96.31
Step [3900/12467], Loss: 0.0778, Acc : 96.31
Step [4000/12467], Loss: 0.0777, Acc : 96.31
Step [4100/12467], Loss: 0.0776, Acc : 96.31
Step [4200/12467], Loss: 0.0774, Acc : 96.32
Step [4300/12467], Loss: 0.0772, Acc : 96.32
Step [4400/12467], Loss: 0.0771, Acc : 96.33
Step [4500/12467], Loss: 0.0770, Acc : 96.34
Step [4600/12467], Loss: 0.0769, Acc : 96.34
Step [4700/12467], Loss: 0.0768, Acc : 96.35
Step [4800/12467], Loss: 0.0768, Acc : 96.34
Step [4900/12467], Loss: 0.0768, Acc : 96.34
Step [5000/12467], Loss: 0.0767, Acc : 96.35
Step [5100/12467], Loss: 0.0767, Acc : 96.35
Step [5200/12467], Loss: 0.0766, Acc : 96.35
Step [5300/12467], Loss: 0.0765, Acc : 96.36
Step [5400/12467], Loss: 0.0764, Acc : 96.36
Step [5500/12467], Loss: 0.0763, Acc : 96.36
Step [5600/12467], Loss: 0.0763, Acc : 96.37
Step [5700/12467], Loss: 0.0761, Acc : 96.38
Step [5800/12467], Loss: 0.0760, Acc : 96.38
Step [5900/12467], Loss: 0.0759, Acc : 96.39
Step [6000/12467], Loss: 0.0759, Acc : 96.39
Step [6100/12467], Loss: 0.0757, Acc : 96.40
Step [6200/12467], Loss: 0.0757, Acc : 96.40
Step [6300/12467], Loss: 0.0756, Acc : 96.40
Step [6400/12467], Loss: 0.0755, Acc : 96.40
Step [6500/12467], Loss: 0.0754, Acc : 96.41
Step [6600/12467], Loss: 0.0753, Acc : 96.41
Step [6700/12467], Loss: 0.0752, Acc : 96.42
Step [6800/12467], Loss: 0.0751, Acc : 96.42
Step [6900/12467], Loss: 0.0750, Acc : 96.43
Step [7000/12467], Loss: 0.0749, Acc : 96.43
Step [7100/12467], Loss: 0.0748, Acc : 96.44
Step [7200/12467], Loss: 0.0747, Acc : 96.44
Step [7300/12467], Loss: 0.0746, Acc : 96.44
Step [7400/12467], Loss: 0.0745, Acc : 96.45
Step [7500/12467], Loss: 0.0744, Acc : 96.45
Step [7600/12467], Loss: 0.0744, Acc : 96.45
Step [7700/12467], Loss: 0.0743, Acc : 96.46
Step [7800/12467], Loss: 0.0742, Acc : 96.46
Step [7900/12467], Loss: 0.0741, Acc : 96.46
Step [8000/12467], Loss: 0.0740, Acc : 96.47
Step [8100/12467], Loss: 0.0740, Acc : 96.47
Step [8200/12467], Loss: 0.0739, Acc : 96.47
Step [8300/12467], Loss: 0.0738, Acc : 96.47
Step [8400/12467], Loss: 0.0737, Acc : 96.48
Step [8500/12467], Loss: 0.0737, Acc : 96.48
Step [8600/12467], Loss: 0.0736, Acc : 96.48
Step [8700/12467], Loss: 0.0736, Acc : 96.48
Step [8800/12467], Loss: 0.0736, Acc : 96.48
Step [8900/12467], Loss: 0.0735, Acc : 96.48
Step [9000/12467], Loss: 0.0734, Acc : 96.49
Step [9100/12467], Loss: 0.0734, Acc : 96.49
Step [9200/12467], Loss: 0.0734, Acc : 96.49
Step [9300/12467], Loss: 0.0734, Acc : 96.49
Step [9400/12467], Loss: 0.0733, Acc : 96.49
Step [9500/12467], Loss: 0.0732, Acc : 96.49
Step [9600/12467], Loss: 0.0733, Acc : 96.49
Step [9700/12467], Loss: 0.0732, Acc : 96.50
Step [9800/12467], Loss: 0.0731, Acc : 96.50
Step [9900/12467], Loss: 0.0731, Acc : 96.50
Step [10000/12467], Loss: 0.0730, Acc : 96.50
Step [10100/12467], Loss: 0.0729, Acc : 96.51
Step [10200/12467], Loss: 0.0729, Acc : 96.51
Step [10300/12467], Loss: 0.0728, Acc : 96.51
Step [10400/12467], Loss: 0.0728, Acc : 96.51
Step [10500/12467], Loss: 0.0727, Acc : 96.52
Step [10600/12467], Loss: 0.0727, Acc : 96.52
Step [10700/12467], Loss: 0.0726, Acc : 96.52
Step [10800/12467], Loss: 0.0726, Acc : 96.52
Step [10900/12467], Loss: 0.0725, Acc : 96.52
Step [11000/12467], Loss: 0.0724, Acc : 96.53
Step [11100/12467], Loss: 0.0724, Acc : 96.53
Step [11200/12467], Loss: 0.0723, Acc : 96.53
Step [11300/12467], Loss: 0.0722, Acc : 96.53
Step [11400/12467], Loss: 0.0722, Acc : 96.53
Step [11500/12467], Loss: 0.0721, Acc : 96.53
Step [11600/12467], Loss: 0.0721, Acc : 96.54
Step [11700/12467], Loss: 0.0721, Acc : 96.54
Step [11800/12467], Loss: 0.0720, Acc : 96.54
Step [11900/12467], Loss: 0.0720, Acc : 96.54
Step [12000/12467], Loss: 0.0719, Acc : 96.55
Step [12100/12467], Loss: 0.0718, Acc : 96.55
Step [12200/12467], Loss: 0.0717, Acc : 96.55
Step [12300/12467], Loss: 0.0717, Acc : 96.55
Step [12400/12467], Loss: 0.0716, Acc : 96.56
Training time for 2 is 233.83883786201477
Validation . . .
Loss 0.1321,  Acc 95.86,  IoU 0.5171
Testing best epoch . . .
Loss 0.4509,  Acc 89.59,  IoU 0.4600