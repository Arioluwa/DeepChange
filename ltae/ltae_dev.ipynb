{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82866ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from models.stclassifier import dLtae\n",
    "from models.ltae import LTAE\n",
    "\n",
    "from utils import load_npz\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6592965-bc38-4639-a80d-1b9d734487cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SITSData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98be021-27e2-4e7e-9e18-eb2719ffd03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87971f4f-728e-4994-ab30-0eefb60993de",
   "metadata": {},
   "outputs": [],
   "source": [
    "js = '../../../results/ltae/trials/conf.json'\n",
    "js = json.load(open(js))\n",
    "# in_channels = js['in_channels']\n",
    "# n_head = js['n_head']\n",
    "# d_k = js['d_k']\n",
    "# n_neurons = js['n_neurons']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7b9615-c3ef-463a-a8fa-4bdcaa3941d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aef48ef-3dce-4ef6-9318-72ff2a28f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = '../../../results/ltae/trials/Seed_0/model.pth.tar'\n",
    "state_dict = torch.load(m)['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce9d097-bdba-4d9d-9f77-62e95d3dc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da4cdaa-cbbd-49b6-8a27-9bb3aceac9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_dict['temporal_encoder.position_enc.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e766de31-810d-4197-bc27-c4e2e25561ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dLtae(in_channels = js['in_channels'], n_head = js['n_head'], d_k= js['d_k'], n_neurons=js['n_neurons'], dropout=js['dropout'], d_model= js['d_model'],\n",
    "                 mlp = js['mlp4'], T =js['T'], len_max_seq = js['len_max_seq'], \n",
    "              positions=None, return_att=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8528eb59-c44e-4515-b69e-49f3f0d4855e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66d9f2-0554-4547-ab7c-2f9e0c7c6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2161d2cf-0b4e-498a-8735-da1570520d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = '../../../results/ltae/trials/Seed_0/model.pth.tar'\n",
    "\n",
    "# model.load_state_dict(torch.load(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b868824b-0cb2-4ef6-899b-59ed599f50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write a function to plot the curves\n",
    "def plot_curve(data):\n",
    "    data = json.load(open(data))\n",
    "    \n",
    "    epoch =range(1, len(data)+1)\n",
    "    # Loss\n",
    "    train_loss = [data[str(i)]['train_loss'] for i in epoch]\n",
    "    val_loss = [data[str(i)]['val_loss'] for i in epoch]\n",
    "    # Accuracy\n",
    "    train_accuracy = [data[str(i)]['train_accuracy'] for i in epoch]\n",
    "    val_accuracy = [data[str(i)]['val_accuracy'] for i in epoch]\n",
    "    # IOU\n",
    "    train_IoU = [data[str(i)]['train_IoU'] for i in epoch]\n",
    "    val_IoU = [data[str(i)]['val_IoU'] for i in epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e22c9fe-bd63-47f3-ab11-e2fca1c0fe8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def date_positions(gfdate_path):\n",
    "    with open(gfdate_path, \"r\") as f:\n",
    "        out_date_list = f.readlines()\n",
    "    out_date_list = [x.strip() for x in out_date_list]\n",
    "    out_date_list = [datetime.datetime.strptime(x, \"%Y%m%d\").timetuple().tm_yday for x in out_date_list]\n",
    "    string_date_list = [x for x in out_date_list]\n",
    "    return string_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba89faf-2ff1-4f60-a5e8-e0de805f4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = time.time()\n",
    "# t = date_positions(\"dates.txt\")\n",
    "# s = date_positions(\"dates.txt\")\n",
    "# print(t)\n",
    "# print(s)\n",
    "# print(\"time: \", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4bae7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0354f6-6fab-4408-9bf8-049de825ae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed value:  9\n",
      "Read set ids completed: 0.009698629379272461 second\n"
     ]
    }
   ],
   "source": [
    "def generate_ids():\n",
    "    \"\"\"\n",
    "    Descr: \n",
    "        Aim: To write and returns the partition (Train, Validation and Test) ids \n",
    "        with respect to the grid split index (range 1 - 100)\n",
    "        \n",
    "        - A random seed value is set within a random intger 1-10,\n",
    "        - the set is spltted into 80:10:10,\n",
    "        - save into a text file with the seed value used\n",
    "    \"\"\"\n",
    "    # set a random seed value within the range 1 -10 \n",
    "    start_time = time.time()\n",
    "    seed_value = 9\n",
    "    # seed_value = np.random.randint(0,10)\n",
    "    np.random.seed(seed_value)\n",
    "    # # block id range 1 - 100 (splitted grid)\n",
    "    block_range = np.arange(1, 101)\n",
    "\n",
    "    # Train, Validation and Test\n",
    "    random.shuffle(block_range)\n",
    "    train_id = block_range[:60] # 60%\n",
    "    val_id = block_range[60:80] # 20%\n",
    "    test_id = block_range[80:] # 20%\n",
    "    print(\"Seed value: \", seed_value)\n",
    "    \n",
    "    if not os.path.exists(\"./ids/train_val_eval_seed_\" + str(seed_value)+\".txt\"):\n",
    "        with open(\"./ids/train_val_eval_seed_\" + str(seed_value)+\".txt\", \"w\") as f:\n",
    "            f.write(\"Training: \" + str(list(train_id)) + \"\\n\")\n",
    "            f.write(\"Validation: \" + str(list(val_id)) + \"\\n\")\n",
    "            f.write(\"Testing: \" + str(list(test_id)) + \"\\n\")\n",
    "            f.close()\n",
    "    print('Read set ids completed: %s second' % (time.time() - start_time))\n",
    "generate_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "276ef82d-965b-4daa-bb1d-29d4d017d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ids(seed_value):\n",
    "    \"\"\"\n",
    "    Read ids from file\n",
    "    \"\"\"\n",
    "    assert seed_value >= 0 and seed_value <= 10\n",
    "    \n",
    "    with open(\"./ids/train_val_eval_seed_\" + str(seed_value)+\".txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        Train_ids = eval(lines[0].split(\":\")[1])\n",
    "        Val_ids = eval(lines[1].split(\":\")[1])\n",
    "        test_ids = eval(lines[2].split(\":\")[1])\n",
    "    return Train_ids, Val_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09eda6b1-6b84-4958-bedc-d1d7b09ab679",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_ids, Val_ids, test_ids = read_ids(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c54f52d-491e-4370-a655-fbe313d4a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = Val_ids + test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5829fcc8-8d68-48c8-a782-f14ca40a88e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fec2129-501a-494e-9391-0082163b4803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80, 39, 18, 65, 81, 8, 94, 76, 93, 32]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cfa68ac-d630-4be7-9663-86f3e22e37dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[79, 82, 34, 30, 46, 20, 9, 7, 23, 45, 80, 39, 18, 65, 81, 8, 94, 76, 93, 32]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d45cfe-a8f6-4922-9964-ce63bed9c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(source_sits, target_sits, case):\n",
    "    \"\"\"\n",
    "    Descr: Compute mean and std for each channel\n",
    "    Input: both SITS dataset(.npz) paths\n",
    "            Case[1 - 3]:\n",
    "            1 - concatenate both dataset, while 2 & 3 rep source and target respectively\n",
    "    The data(from N,LxD) is reshaped into (N,D,L);\n",
    "        where N - pixel, D - Bands (10), L - Time (33)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # case = 1: both, case = 2: target, case = 3: target\n",
    "    if case == 1:\n",
    "        sits = [source_sits, target_sits]\n",
    "    elif case == 2:\n",
    "        sits = source_sits\n",
    "    elif case == 3:\n",
    "        sits = target_sits\n",
    "    else:\n",
    "        print('Select case between 1-3')\n",
    "        return None\n",
    "    \n",
    "    # if sits is a list, then it's a list of paths\n",
    "    if isinstance(sits, list):\n",
    "        # load data\n",
    "        X_source = np.load(sits[0])['X']\n",
    "        X_target = np.load(sits[1])['X']\n",
    "        # concatenate the data\n",
    "        X = np.concatenate((X_source, X_target), axis=0)\n",
    "    # if sits is a string, then it's a path\n",
    "    else: \n",
    "        with np.load(sits) as data:\n",
    "            X = data['X']\n",
    "\n",
    "    X = X.reshape(X.shape[0], n_channel, int(X.shape[1]/n_channel))\n",
    "    # compute mean and std\n",
    "    X_mean = np.mean(X, axis=(0,2))\n",
    "    X_std = np.std(X, axis=(0,2))\n",
    "    print('mean shape: ', X_mean.shape)\n",
    "    print('std shape: ', X_std.shape)\n",
    "    # save X_mean and X_std sepearately for sits as txt file\n",
    "    np.savetxt(os.path.join('mean_'+ str(case) +'.txt'), X_mean)\n",
    "    np.savetxt(os.path.join('std_'+ str(case) +'.txt'), X_std)\n",
    "\n",
    "# for i in [1,2,3]:\n",
    "#     start_time = time.time()\n",
    "#     source_path = \"../../../data/theiaL2A_zip_img/output/2018/2018_SITS_data.npz\"\n",
    "#     target_path = \"../../../data/theiaL2A_zip_img/output/2019/2019_SITS_data.npz\"\n",
    "#     compute_mean_std(source_path, target_path, i)\n",
    "#     print(\"run time: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d277504e-263a-44ba-81b3-ecc67ccf65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_stdv2(sits, domain='source'):\n",
    "    \"\"\"\n",
    "    Descr: Compute mean and std for each channel\n",
    "    Input: both SITS dataset(.npz) paths\n",
    "    The data(from N,LxD) is reshaped into (N,D,L);\n",
    "        where N - pixel, D - Bands (10), L - Time (33)\n",
    "    \"\"\"\n",
    "    with np.load(sits) as data:\n",
    "            X = data['X']\n",
    "\n",
    "    X = X.reshape(X.shape[0], n_channel, int(X.shape[1]/n_channel))\n",
    "    # compute mean and std\n",
    "    X_mean = np.mean(X, axis=(0,2))\n",
    "    X_std = np.std(X, axis=(0,2))\n",
    "    print('mean shape: ', X_mean.shape)\n",
    "    print('std shape: ', X_std.shape)\n",
    "    # save X_mean and X_std sepearately for sits as txt file\n",
    "    np.savetxt(os.path.join('./mean_std/', domain + '_mean.txt'), X_mean)\n",
    "    np.savetxt(os.path.join('./mean_std/', domain + '_std.txt'), X_std)\n",
    "\n",
    "source_path = '../../../data/theiaL2A_zip_img/output/2018/2018_SITS_subset_data.npz'\n",
    "target_path = '../../../data/theiaL2A_zip_img/output/2019/2019_SITS_subset_data.npz'\n",
    "# compute_mean_stdv2(source_path, 'source')\n",
    "# compute_mean_stdv2(target_path, domain = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d4055b3-c150-4215-9576-9569a415ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SITSDatav2(data.Dataset):\n",
    "    def __init__(self, sits, seed, partition='train', transform=None):\n",
    "        \n",
    "        self.sits = sits\n",
    "        self.seed = seed\n",
    "        self.transform = transform\n",
    "        \n",
    "        # get partition ids using the read_id() func\n",
    "        start_time = time.time()\n",
    "        self.train_ids, self.val_ids, self.test_ids = read_ids(self.seed)\n",
    "        print(\"read ids completed: %s second\" % (time.time() - start_time))\n",
    "\n",
    "        # select partition\n",
    "        if partition == 'train':\n",
    "            self.ids = self.train_ids\n",
    "        elif partition == 'val':\n",
    "            self.ids = self.val_ids\n",
    "        elif partition == 'test':\n",
    "            self.ids = self.test_ids\n",
    "        else:\n",
    "            raise ValueError('Invalid partition: {}'.format(partition))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        print('reading files....')\n",
    "        X, y, block_ids = load_npz(self.sits)\n",
    "        print(\"load npz: %s seconds\" % (time.time() - start_time))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        y = np.unique(y, return_inverse=True)[1]\n",
    "        print(\"reassigning %s seconds\" % (time.time() - start_time))\n",
    "        \n",
    "        # concatenate the data\n",
    "        start_time = time.time()\n",
    "        data_ = np.concatenate((X, y[:, None], block_ids[:, None]), axis=1)\n",
    "        print(\"Concatenating completed: %s seconds\" % (time.time() - start_time))\n",
    "\n",
    "        # filter by block_id\n",
    "        start_time = time.time()\n",
    "        data_ = data_[np.isin(data_[:, -1], self.ids)]\n",
    "        print(\"filtering ids completed: %s seconds\" % (time.time() - start_time))\n",
    "        \n",
    "        self.X_ = data_[:, :-2]\n",
    "        self.y_ = data_[:, -2]                          \n",
    "        \n",
    "        del X\n",
    "        del y\n",
    "        del block_ids\n",
    "        del data_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_time = time.time()\n",
    "        self.X = self.X_[idx]\n",
    "        self.y = self.y_[idx]\n",
    "        print(\"getting data: %s seconds\" % ((time.time() - start_time)*100))\n",
    "\n",
    "        start_time = time.time()\n",
    "        self.X = np.array(self.X).astype('float32')\n",
    "        self.y = np.array(self.y).astype('float32')\n",
    "        print(\"conversion: %s seconds\" % ((time.time() - start_time)*100))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.X = self.X.reshape(int(self.X.shape[0]/n_channel), n_channel)\n",
    "        print(\"reshape data: %s seconds\" % ((time.time() - start_time)*100))\n",
    "\n",
    "        # transform\n",
    "        start_time = time.time()\n",
    "        if self.transform:\n",
    "            self.X = self.transform(self.X)\n",
    "        print(\"transform data: %s seconds\" % ((time.time() - start_time)*100))\n",
    "        print(self.X.shape)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        torch_x = torch.from_numpy(self.X)\n",
    "        torch_y = torch.from_numpy(self.y)\n",
    "        print(\"tensor: %s seconds\" % ((time.time() - start_time)*100))\n",
    "        \n",
    "        return torch_x, torch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8190c2ef-d5ca-4ace-8b0b-34c6d4dc3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "class standardize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return (sample - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9aa04b1-cd97-4f62-8bef-cb40c4c0b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ids completed: 0.001961231231689453 second\n",
      "reading files....\n",
      "load npz: 7.151129961013794 seconds\n",
      "reassigning 0.0646812915802002 seconds\n",
      "Concatenating completed: 1.7340800762176514 seconds\n",
      "filtering ids completed: 1.6481618881225586 seconds\n"
     ]
    }
   ],
   "source": [
    "mean = np.loadtxt('./mean_std/source_mean.txt')\n",
    "std = np.loadtxt('./mean_std/source_std.txt')\n",
    "seed = 0 \n",
    "transform = transforms.Compose([standardize(mean, std)])\n",
    "\n",
    "# paths\n",
    "source_path = '../../../data/theiaL2A_zip_img/output/2018/2018_SITS_subset_data.npz'\n",
    "# target_path = '../../../data/theiaL2A_zip_img/output/2019/2019_SITS_subset_data.npz'\n",
    "\n",
    "train_dataset = SITSDatav2(source_path, seed, partition='train', transform=transform)\n",
    "# val_dataset = SITSDatav2(source_path, seed, partition='val', transform=transform)\n",
    "# test_dataset = SITSDatav2(source_path, seed, partition='test', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcd1385b-6909-4257-b631-68d733493857",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = '../../../data/theiaL2A_zip_img/output/2018/2018_SITS_subset_data.npz'\n",
    "X, y, _ = load_npz(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8748f0a9-610b-4951-bb7b-594165d7d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_ = {0:1, \n",
    "#         1:2, \n",
    "#         2:3, \n",
    "#         3:4, \n",
    "#         4:5, \n",
    "#         5:6, \n",
    "#         6:7,\n",
    "#         7:8,\n",
    "#         8:9,\n",
    "#         9:10,\n",
    "#         10:12,\n",
    "#         11:13,\n",
    "#         12:14,\n",
    "#         13:15,\n",
    "#         14:16,\n",
    "#         15:17,\n",
    "#         16:18,\n",
    "#         17:19,\n",
    "#         18:23}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7ba0963-5865-4c59-9067-044b9fbfdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_uniq = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49b786d5-7808-4a39-beab-4ff547a5dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_revs_uniq = np.unique(np.unique(y, return_inverse=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6caadcdd-e26e-4ab0-ae24-9ee7a1dc462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 2: 1,\n",
       " 3: 2,\n",
       " 4: 3,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 6,\n",
       " 8: 7,\n",
       " 9: 8,\n",
       " 10: 9,\n",
       " 12: 10,\n",
       " 13: 11,\n",
       " 14: 12,\n",
       " 15: 13,\n",
       " 16: 14,\n",
       " 17: 15,\n",
       " 18: 16,\n",
       " 19: 17,\n",
       " 23: 18}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict__ = dict(zip(y_uniq, y_revs_uniq))\n",
    "dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba679ae1-c74c-4f5e-b1ce-9458340153e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = [dict__[i] for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac64ba86-8c6b-420a-ab89-75c4e9333788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6b2cb17-21dd-4ba1-9d81-57415709abe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop time 2.462660789489746\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "y = np.unique(y, return_inverse=True)[1]\n",
    "\n",
    "y_train_mapped = np.zeros(y.shape)\n",
    "for i in range(y.shape[0]):\n",
    "        y_train_mapped[i] = dict_[y[i]]\n",
    "print(\"stop time\", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d39220f7-a692-4ff9-94a2-200bba8e9ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LTAE'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_model =['RF', 'LTAE']\n",
    "str_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b22e7e-87e6-4442-bb10-3dafaa4d621e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 12., 13., 14.,\n",
       "       15., 16., 17., 18., 19., 23.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee1dddbc-4ba3-41e6-9496-b341ec9376ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 10784283, Val 1606360, Test 1701000\n"
     ]
    }
   ],
   "source": [
    "for x, y, z in l_se:\n",
    "    print('Train {}, Val {}, Test {}'.format(len(x), len(y), len(z)))\n",
    "    # print('Starting Fold {}'.format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b331b92-15de-4d5e-9f73-34c56cbab848",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67c0868a-8005-4f15-ab40-47bde5d2a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_todevice(x, device):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.to(device)\n",
    "    else:\n",
    "        return [recursive_todevice(c, device) for c in x]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
