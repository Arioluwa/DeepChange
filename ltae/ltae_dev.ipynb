{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82866ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from models.stclassifier import dLtae\n",
    "from models.ltae import LTAE\n",
    "\n",
    "from utils import load_npz\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87971f4f-728e-4994-ab30-0eefb60993de",
   "metadata": {},
   "outputs": [],
   "source": [
    "js = '../../../results/ltae/trials/conf.json'\n",
    "js = json.load(open(js))\n",
    "# in_channels = js['in_channels']\n",
    "# n_head = js['n_head']\n",
    "# d_k = js['d_k']\n",
    "# n_neurons = js['n_neurons']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7b9615-c3ef-463a-a8fa-4bdcaa3941d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aef48ef-3dce-4ef6-9318-72ff2a28f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = '../../../results/ltae/trials/Seed_0/model.pth.tar'\n",
    "state_dict = torch.load(m)['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce9d097-bdba-4d9d-9f77-62e95d3dc605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('temporal_encoder.inconv.0.weight',\n",
       "              tensor([[[ 0.6568],\n",
       "                       [ 1.6304],\n",
       "                       [ 0.4410],\n",
       "                       ...,\n",
       "                       [ 0.4231],\n",
       "                       [ 0.7069],\n",
       "                       [-0.3942]],\n",
       "              \n",
       "                      [[-1.0331],\n",
       "                       [ 0.9314],\n",
       "                       [ 0.6253],\n",
       "                       ...,\n",
       "                       [-2.3112],\n",
       "                       [ 0.5935],\n",
       "                       [-1.8847]],\n",
       "              \n",
       "                      [[-0.2114],\n",
       "                       [-0.8515],\n",
       "                       [-1.7348],\n",
       "                       ...,\n",
       "                       [-1.5654],\n",
       "                       [-2.1286],\n",
       "                       [-0.3857]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 2.5021],\n",
       "                       [-1.0580],\n",
       "                       [-0.3950],\n",
       "                       ...,\n",
       "                       [-1.0732],\n",
       "                       [ 1.6504],\n",
       "                       [-0.5099]],\n",
       "              \n",
       "                      [[ 0.0902],\n",
       "                       [ 0.1626],\n",
       "                       [-0.5532],\n",
       "                       ...,\n",
       "                       [-0.3368],\n",
       "                       [ 0.4904],\n",
       "                       [ 1.0701]],\n",
       "              \n",
       "                      [[-1.8364],\n",
       "                       [ 0.6126],\n",
       "                       [ 1.4432],\n",
       "                       ...,\n",
       "                       [-1.1260],\n",
       "                       [-0.2928],\n",
       "                       [-1.1900]]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.inconv.0.bias',\n",
       "              tensor([ 3.8627e-01,  1.7657e+00, -3.1691e-01, -1.3093e+00, -1.0825e+00,\n",
       "                       5.1727e-01, -5.0118e-01,  9.8483e-01,  1.0002e-01,  1.5829e+00,\n",
       "                       6.2427e-01,  1.4756e-01, -1.3868e-01, -6.6229e-01, -6.8787e-01,\n",
       "                       2.1761e-02,  2.0829e+00,  7.0878e-01, -5.8707e-01,  7.7518e-01,\n",
       "                       4.8093e-01,  1.5826e+00,  1.4430e+00, -3.0777e-01, -1.8172e+00,\n",
       "                      -2.4715e+00, -1.0928e-01, -1.3392e+00,  6.1844e-01,  3.6846e-01,\n",
       "                      -4.4467e-01, -2.3999e-01,  8.3572e-01,  1.5164e+00,  1.6325e-02,\n",
       "                      -6.5390e-01, -7.4037e-02, -8.5783e-01,  2.3886e-01, -5.3441e-01,\n",
       "                       8.2929e-01, -8.4358e-01, -1.0638e+00, -2.5039e-01,  1.6193e-01,\n",
       "                       1.2366e-01,  3.0557e-01,  1.0833e+00, -5.3359e-01,  4.7041e-01,\n",
       "                       4.9902e-02,  3.4017e-01, -1.0432e+00,  1.7438e+00, -4.1402e-01,\n",
       "                      -7.7502e-01,  1.1271e+00,  5.9654e-01, -4.0966e-01,  2.3658e-01,\n",
       "                      -7.8091e-01, -2.1257e-01, -2.7941e-01,  6.7861e-02, -1.4864e+00,\n",
       "                      -6.9734e-01,  7.3096e-01, -3.2958e-01,  1.1630e+00,  1.3291e+00,\n",
       "                      -8.3840e-01, -1.4656e+00,  2.8612e-01,  1.8657e-03,  1.8758e-02,\n",
       "                       3.0916e-01,  7.6712e-01,  2.7121e-02, -3.6363e-01, -1.2826e+00,\n",
       "                       6.3760e-02, -6.7081e-01, -1.1537e+00, -1.3633e+00, -5.7032e-02,\n",
       "                       1.7908e-01,  8.2524e-01, -1.1701e+00,  1.1638e+00,  5.6894e-01,\n",
       "                       3.4643e-01, -1.5259e+00,  3.7940e-01,  1.0212e-01,  7.3932e-01,\n",
       "                       5.6962e-01,  9.0326e-01,  7.9684e-01, -1.2058e-01,  9.0546e-01,\n",
       "                      -4.6959e-01,  5.4827e-01,  8.4195e-01, -1.1151e+00, -3.9933e-01,\n",
       "                       4.5137e-01, -1.2542e+00, -1.5262e+00,  2.5178e-02,  1.4924e+00,\n",
       "                      -6.8222e-01, -6.9828e-01, -2.7394e+00, -1.3119e-01, -1.7482e+00,\n",
       "                       1.7878e-01, -1.2613e+00,  3.5085e-01, -2.5123e-01, -9.0537e-01,\n",
       "                       3.2464e-01, -1.0087e+00,  8.0088e-02, -4.0054e-01,  8.8767e-01,\n",
       "                       1.3946e+00,  1.0510e-01, -1.2281e+00,  1.4106e+00, -3.9312e-01,\n",
       "                      -1.6413e+00,  8.2476e-02, -6.4475e-01,  1.0419e+00, -4.8045e-01,\n",
       "                      -1.3682e+00,  3.1521e-01, -3.6073e-01, -6.8523e-01, -6.1613e-01,\n",
       "                      -1.3103e+00,  1.2207e+00, -3.7300e-01, -7.1067e-01, -1.7904e-01,\n",
       "                       6.4487e-01,  1.2953e+00,  2.4435e-01,  3.9965e-01,  5.2237e-01,\n",
       "                       1.2617e+00, -4.2434e-01,  4.0485e-01,  1.0277e+00,  7.9812e-01,\n",
       "                      -1.9551e-04,  1.1878e+00,  2.9933e-01,  1.1520e+00, -1.0064e+00,\n",
       "                      -2.0494e-01,  2.4707e+00,  9.2420e-01,  2.7918e-01,  1.1461e+00,\n",
       "                      -1.1129e+00, -4.6862e-01, -2.6371e+00, -7.5763e-01,  2.5057e-01,\n",
       "                      -1.5323e-01,  5.0182e-01, -4.9989e-01, -1.4033e+00,  4.7896e-02,\n",
       "                      -2.8414e-01,  5.7804e-01, -2.0714e-01, -7.8644e-01, -7.1321e-01,\n",
       "                      -8.1927e-01, -9.1063e-01,  9.0649e-01,  4.8370e-02, -7.0828e-01,\n",
       "                       2.7516e-01,  5.2160e-01, -2.2143e+00,  5.1404e-01, -6.0106e-01,\n",
       "                      -9.6790e-01, -8.5521e-01, -3.7256e-01, -2.0899e-01, -1.0014e+00,\n",
       "                      -3.7580e-02,  1.9157e+00,  9.1768e-02,  2.0383e+00, -2.1395e-01,\n",
       "                      -6.3946e-01,  5.4818e-02, -3.8489e-02, -1.7335e+00, -3.3251e-01,\n",
       "                       6.8629e-01,  6.7927e-01,  4.8583e-01,  5.2250e-01, -3.9798e-01,\n",
       "                       6.8198e-01, -1.7254e+00,  1.5103e+00,  5.1910e-02, -1.1176e+00,\n",
       "                       7.1641e-01, -1.0981e+00, -1.4979e+00, -6.5965e-01,  1.2202e+00,\n",
       "                       1.3295e+00,  3.3415e-01, -1.0774e+00, -1.4280e+00,  4.4915e-01,\n",
       "                       1.9408e+00, -3.6234e-01, -3.8724e-01,  1.2377e-02,  1.1610e+00,\n",
       "                      -1.8053e+00,  1.2126e+00, -2.5832e+00, -4.8328e-01,  1.4569e+00,\n",
       "                       8.3472e-01,  4.4228e-01, -6.5846e-01,  2.0587e-01, -4.6668e-01,\n",
       "                       7.4680e-02, -3.7255e-01, -1.1442e-01,  8.8373e-01, -5.6578e-01,\n",
       "                       2.2516e-01, -1.8691e-01,  2.0807e-02, -6.7750e-01, -7.6363e-01,\n",
       "                       5.2732e-01, -2.7269e-01, -4.9372e-01, -4.6000e-01,  6.2548e-01,\n",
       "                      -1.4885e+00], device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.inconv.1.weight',\n",
       "              tensor([[0.3755, 0.4790, 0.2042,  ..., 0.9790, 0.5734, 1.1964],\n",
       "                      [0.8613, 0.7262, 0.5978,  ..., 0.8255, 0.8248, 0.4484],\n",
       "                      [1.1275, 1.0066, 0.8565,  ..., 0.6083, 0.9102, 0.9346],\n",
       "                      ...,\n",
       "                      [0.7414, 0.6734, 0.5160,  ..., 0.9534, 0.5084, 0.5287],\n",
       "                      [1.2845, 1.4709, 1.1211,  ..., 0.7388, 0.7632, 1.0839],\n",
       "                      [0.8685, 0.9801, 0.9554,  ..., 0.7672, 1.1465, 1.1920]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.inconv.1.bias',\n",
       "              tensor([[ 2.3415e-01,  1.2806e-01,  2.8927e-01,  ...,  8.7438e-03,\n",
       "                        1.4382e-01, -1.7150e-01],\n",
       "                      [-5.4224e-01, -3.1339e-01, -1.0758e-01,  ..., -1.8626e-01,\n",
       "                        2.9659e-03,  1.8685e-01],\n",
       "                      [ 1.5716e-01, -2.7818e-02, -2.6267e-01,  ...,  3.2634e-02,\n",
       "                        1.0438e-01, -1.4708e-01],\n",
       "                      ...,\n",
       "                      [-8.6254e-02, -1.8928e-01, -2.4075e-01,  ..., -4.0644e-01,\n",
       "                        1.6290e-01,  3.9096e-04],\n",
       "                      [ 1.2104e-01,  1.4244e-01,  1.3033e-01,  ..., -2.2212e-01,\n",
       "                        3.1708e-01,  7.7090e-02],\n",
       "                      [-8.3803e-02, -1.0218e-01, -1.4630e-01,  ..., -8.3669e-02,\n",
       "                       -1.2223e-01, -5.9502e-04]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.position_enc.weight',\n",
       "              tensor([[ 0.0000,  1.0000,  0.0000,  ...,  1.0000,  0.0000,  1.0000],\n",
       "                      [ 0.8415,  0.5403,  0.4093,  ...,  1.0000,  0.0024,  1.0000],\n",
       "                      [ 0.9093, -0.4161,  0.7469,  ...,  0.9999,  0.0047,  1.0000],\n",
       "                      ...,\n",
       "                      [-0.4040,  0.9147,  0.4849,  ...,  0.9848,  0.0734,  0.9973],\n",
       "                      [ 0.5514,  0.8342,  0.8004,  ...,  0.9839,  0.0758,  0.9971],\n",
       "                      [ 0.9999, -0.0133,  0.9756,  ...,  0.9828,  0.0782,  0.9969]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.inlayernorm.weight',\n",
       "              tensor([1.1182, 1.1286, 1.0113, 1.1906, 1.2089, 1.0575, 0.5860, 0.9065, 0.8357,\n",
       "                      0.8720], device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.inlayernorm.bias',\n",
       "              tensor([ 0.6751,  0.6400,  0.5842,  0.3890, -0.3710, -0.3538, -0.3120, -0.6100,\n",
       "                      -0.2292, -0.0387], device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.outlayernorm.weight',\n",
       "              tensor([1.4034, 1.0401, 0.9457, 0.9104, 1.2163, 0.8541, 1.2267, 1.1278, 0.8408,\n",
       "                      1.0590, 1.3075, 1.1060, 0.9569, 1.2747, 0.9952, 1.0990, 0.8775, 0.8371,\n",
       "                      0.9427, 0.8015, 0.6708, 1.0534, 0.9384, 1.2800, 1.0874, 1.0566, 0.7070,\n",
       "                      1.2147, 1.1443, 1.2671, 1.3264, 1.1429, 1.2006, 1.2791, 1.2781, 1.2891,\n",
       "                      0.8707, 1.2678, 1.0019, 0.6631, 0.8957, 1.1066, 1.4256, 0.9690, 1.2417,\n",
       "                      1.3204, 1.1896, 0.8090, 1.5434, 0.3815, 0.8209, 1.2565, 0.7177, 0.9884,\n",
       "                      1.0855, 1.1145, 1.3721, 0.9049, 1.2063, 1.6168, 1.2672, 1.1267, 1.3555,\n",
       "                      1.3947, 0.9926, 1.1733, 0.8332, 0.9305, 0.9085, 0.8840, 1.2478, 1.0095,\n",
       "                      0.8727, 1.1335, 0.8723, 1.0841, 0.6745, 1.3686, 1.9638, 0.9314, 1.0045,\n",
       "                      0.4611, 1.0831, 1.0464, 0.8364, 0.9579, 1.2682, 1.1735, 1.1141, 1.0473,\n",
       "                      0.9112, 1.0578, 1.4132, 1.1603, 1.5190, 1.0364, 1.1237, 1.1380, 0.8394,\n",
       "                      0.8806, 1.2972, 0.7640, 0.9263, 0.6037, 1.1190, 0.9088, 1.0772, 0.6454,\n",
       "                      0.9859, 1.1286, 1.4209, 1.1150, 0.6786, 1.2058, 0.9502, 0.6660, 1.5650,\n",
       "                      1.0522, 1.0620, 1.1234, 1.3136, 0.5678, 1.1688, 1.2735, 0.7793, 0.7033,\n",
       "                      1.0646, 0.8360], device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.outlayernorm.bias',\n",
       "              tensor([ 8.7771e-12, -1.3125e-11,  3.2988e-13,  6.8033e-12,  1.2389e-11,\n",
       "                      -1.1365e-11, -1.6131e-11, -7.5206e-12,  6.0154e-12, -6.2607e-12,\n",
       "                       5.5381e-12, -3.9137e-12,  6.9761e-12,  1.0446e-11, -1.3245e-11,\n",
       "                       1.7598e-11, -2.4836e-12, -1.0958e-12,  9.5614e-13,  4.6720e-13,\n",
       "                      -6.9786e-12, -8.4150e-12, -1.1302e-11, -5.9630e-13,  1.3239e-12,\n",
       "                       1.2626e-11, -5.7417e-12,  2.1987e-12, -1.6842e-11,  1.9054e-11,\n",
       "                       1.3668e-11,  2.6444e-11, -1.9001e-11,  1.4132e-11,  1.3591e-11,\n",
       "                       5.2760e-12, -1.0804e-11, -3.0347e-12,  1.0060e-11,  1.3095e-11,\n",
       "                      -2.6028e-12, -1.8085e-12,  1.8421e-12, -1.9663e-12,  4.3906e-12,\n",
       "                       8.6499e-12,  3.4860e-12,  2.4887e-12,  1.9093e-12, -5.3490e-12,\n",
       "                       2.5356e-11, -2.9596e-11, -2.2195e-11,  1.2979e-11,  2.8735e-12,\n",
       "                       4.8093e-12, -1.6724e-11, -4.5391e-12, -2.1662e-12, -5.6977e-12,\n",
       "                       1.6713e-12, -1.7164e-12, -1.0290e-11, -2.9950e-11, -7.8430e-12,\n",
       "                      -1.2889e-11, -3.8650e-12,  4.8800e-12, -3.7568e-12,  9.5764e-12,\n",
       "                      -1.1577e-11,  1.2086e-11,  1.9723e-11,  5.4562e-12,  6.2207e-12,\n",
       "                      -8.9258e-12,  1.1597e-11,  4.1996e-12,  5.2393e-12,  7.3356e-12,\n",
       "                      -1.8791e-11,  1.3795e-12, -1.1913e-11, -4.8805e-12, -5.0934e-12,\n",
       "                       1.3499e-11,  7.2473e-12, -1.0378e-12, -8.7225e-13, -5.6806e-12,\n",
       "                       2.1295e-11,  5.8995e-12, -7.1172e-12, -1.3645e-12, -3.3600e-12,\n",
       "                       2.0947e-11,  2.1996e-11,  1.1612e-12,  3.7077e-12, -4.7767e-12,\n",
       "                      -3.4725e-12, -4.6501e-15, -3.0534e-12, -4.2069e-12, -1.2982e-11,\n",
       "                       5.8922e-12,  8.4978e-12, -1.4023e-11,  1.1944e-11,  4.5954e-12,\n",
       "                       1.9227e-11,  5.8368e-12, -1.6518e-12, -8.0836e-13,  3.3344e-12,\n",
       "                       2.0805e-11,  9.7882e-13, -1.0435e-13, -5.0777e-12,  3.6277e-12,\n",
       "                      -2.0468e-12, -2.6063e-12, -4.7775e-12,  1.0609e-11,  4.4762e-12,\n",
       "                      -1.0442e-11,  9.3027e-12, -2.1503e-12], device='cuda:0',\n",
       "                     dtype=torch.float64)),\n",
       "             ('temporal_encoder.attention_heads.Q',\n",
       "              tensor([[ 2.0417e-01,  8.3710e-03,  3.5514e-01,  7.1454e-01, -9.1668e-03,\n",
       "                        6.9823e-01, -9.6332e-03, -1.2099e-01],\n",
       "                      [ 1.7291e-01, -3.2073e-02, -9.0242e-01,  6.9242e-02,  3.7036e-01,\n",
       "                        2.8775e-01,  2.8807e-01, -1.8021e-01],\n",
       "                      [ 5.4691e-03, -9.8860e-01,  6.2793e-01,  1.4335e-01, -2.9065e-01,\n",
       "                       -3.5445e-01,  5.4666e-02, -6.3185e-03],\n",
       "                      [ 3.6877e-01, -8.2319e-01, -2.8493e-01,  1.9177e-01, -4.3723e-01,\n",
       "                       -7.6578e-01,  2.1152e-01, -1.4779e-01],\n",
       "                      [ 1.4034e-01, -6.6985e-01, -5.3870e-01,  1.7322e-03, -6.8504e-01,\n",
       "                       -1.4933e-01, -1.2891e-01,  2.6408e-02],\n",
       "                      [-4.5526e-02,  9.9719e-04,  9.3183e-02, -3.7220e-01,  1.1146e+00,\n",
       "                       -1.2416e-02, -1.4922e-01, -6.2792e-01],\n",
       "                      [ 7.2558e-03,  3.0754e-01, -5.3357e-01, -1.2544e-01, -3.5344e-01,\n",
       "                       -5.7977e-02,  8.4886e-03, -1.1510e+00],\n",
       "                      [ 5.4146e-01, -5.4918e-01, -1.6199e-01,  1.8318e-01,  6.3205e-01,\n",
       "                        2.0287e-02, -2.2131e-01, -2.2397e-01],\n",
       "                      [ 4.4228e-01, -7.2242e-02, -3.0696e-02,  7.2286e-01,  5.6621e-01,\n",
       "                       -6.8987e-01, -1.5282e-02, -4.3406e-01],\n",
       "                      [ 7.3427e-01,  4.7120e-01, -5.9015e-01, -2.5189e-01,  2.9228e-03,\n",
       "                       -2.4054e-01,  9.9387e-03,  3.2595e-01],\n",
       "                      [ 2.1086e-01, -3.1987e-01, -1.2020e-01,  2.0682e-01,  6.5140e-02,\n",
       "                       -4.1366e-01, -3.4125e-01,  6.9250e-01],\n",
       "                      [ 9.2889e-01,  9.1789e-02, -1.7662e-01, -3.2124e-01,  2.1106e-01,\n",
       "                       -2.0286e-02,  8.4782e-03, -4.4594e-01],\n",
       "                      [-1.5175e-01,  9.7649e-02,  4.6376e-01,  5.8946e-02, -8.8552e-01,\n",
       "                        3.0655e-02, -6.2455e-02, -1.9277e-01],\n",
       "                      [ 6.4559e-01,  4.2348e-02, -3.8677e-01, -1.4153e-01,  3.6664e-01,\n",
       "                        2.3315e-01, -5.1671e-01, -8.7898e-01],\n",
       "                      [-1.2624e-01,  1.8809e-03,  1.0554e-01, -2.0298e-01,  1.0712e-01,\n",
       "                        1.1882e+00,  7.7289e-01, -2.0060e-04],\n",
       "                      [ 3.6092e-01,  5.6385e-01,  4.0669e-03,  6.7085e-01, -2.6444e-03,\n",
       "                       -1.4941e-01,  1.0663e+00, -2.6201e-01]], device='cuda:0',\n",
       "                     dtype=torch.float64)),\n",
       "             ('temporal_encoder.attention_heads.fc1_k.weight',\n",
       "              tensor([[ 0.0933,  0.1041, -0.0324,  ...,  0.1417, -0.0066, -0.1698],\n",
       "                      [-0.0535,  0.0706, -0.0987,  ...,  0.1359,  0.1548, -0.0972],\n",
       "                      [-0.0507,  0.0210,  0.0674,  ...,  0.3613,  0.0738, -0.1801],\n",
       "                      ...,\n",
       "                      [ 0.0450, -0.0102,  0.0926,  ..., -0.1763,  0.0806,  0.0678],\n",
       "                      [-0.1093,  0.0125, -0.1966,  ...,  0.1217,  0.0364,  0.0125],\n",
       "                      [ 0.0421,  0.1456,  0.1207,  ..., -0.0490,  0.0413,  0.0880]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.attention_heads.fc1_k.bias',\n",
       "              tensor([ 0.6514, -0.6985,  0.6670, -0.7115,  0.2143, -0.9004, -0.4519, -0.5756,\n",
       "                      -1.3789,  0.5017, -0.4649, -1.3959, -0.4357,  0.4052,  0.1395, -0.0721,\n",
       "                       0.6942,  1.6668,  1.3827,  1.3931,  1.0892, -0.8163,  0.7344,  1.2756,\n",
       "                      -1.6169, -0.0267, -0.0071,  0.3490,  1.7172, -0.6040, -0.1903,  1.0611,\n",
       "                       1.0419,  0.8047, -1.0866, -0.3472, -0.0045, -1.4613,  0.7196, -0.7179,\n",
       "                       0.2837, -0.0998,  2.2699,  0.9873,  0.4598,  1.4155, -0.3475, -1.8048,\n",
       "                      -0.0395,  0.7335,  0.5259,  0.2367,  0.7845, -0.4193,  0.2449, -1.2416,\n",
       "                      -1.4266,  0.3543,  1.8879,  0.2089, -0.1894, -1.0356, -0.0826,  0.4312,\n",
       "                      -1.0646, -0.9945, -0.0339, -2.0256, -0.7555, -0.8434, -0.7465, -0.2454,\n",
       "                       0.5182, -0.1980, -1.1928,  0.6668,  0.2955,  1.7246,  1.0309, -0.2611,\n",
       "                      -1.2899,  0.6190,  1.1138,  0.1769, -1.0406, -0.5888, -1.8809,  1.1443,\n",
       "                       1.7550,  2.2934,  0.5553,  1.2395, -0.4073,  0.8992, -0.3001, -0.2246,\n",
       "                      -0.6952, -0.2262, -1.5818, -0.1115, -1.3883,  1.6677, -0.6113,  1.4031,\n",
       "                       0.0088, -0.0747, -2.3374,  1.0315,  0.4637,  1.6526,  0.8899,  0.7585,\n",
       "                      -1.2126, -0.5449,  1.5859, -1.2598, -0.8014,  1.0512, -1.1271, -0.6098,\n",
       "                      -0.0915, -0.3012,  0.7452,  0.2337,  0.6524,  2.5173,  1.3024, -1.2456],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.mlp.0.weight',\n",
       "              tensor([[ 0.1160,  0.1479, -0.0445,  ...,  0.0793,  0.3674, -0.0504],\n",
       "                      [-0.0239,  0.0250, -0.1980,  ...,  0.0466,  0.2249,  0.1134],\n",
       "                      [-0.2015, -0.1076, -0.0875,  ..., -0.5325, -0.2143,  0.0157],\n",
       "                      ...,\n",
       "                      [-0.0995,  0.0376,  0.0275,  ...,  0.2408,  0.0251,  0.1828],\n",
       "                      [-0.0551,  0.0244,  0.1684,  ...,  0.4769, -0.2468, -0.0091],\n",
       "                      [ 0.1569, -0.2345,  0.1081,  ...,  0.1819,  0.0385, -0.0780]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.mlp.0.bias',\n",
       "              tensor([ 0.4465,  0.7089, -1.2765, -0.9549,  1.5027, -1.1772,  0.8688,  0.5210,\n",
       "                       2.6848,  0.3270, -0.4673,  0.3238, -0.2564,  0.9401,  1.8302,  0.1073,\n",
       "                       0.7184, -0.0228, -0.2907,  0.1524, -1.1543, -0.3388,  0.4025,  1.3492,\n",
       "                      -0.0673, -1.0139, -0.9732,  1.0385, -0.5430, -0.1025,  0.9829, -1.5072,\n",
       "                       0.2671,  2.4977,  0.4920,  0.7978,  0.5016, -0.5882, -0.7852,  0.8846,\n",
       "                      -0.6640,  0.3739, -0.9868,  1.2070,  1.5030,  2.4862, -0.9753, -0.9902,\n",
       "                       0.3747,  1.8086,  0.6829,  1.5499, -0.8873, -0.5805, -0.0411,  1.8220,\n",
       "                      -1.0416, -0.0496, -1.1565, -0.7863,  1.4159, -0.0673,  0.4765, -0.0303,\n",
       "                      -1.0563,  1.1078,  0.1579,  0.8372, -1.4825,  0.7926,  1.4132,  0.1047,\n",
       "                       0.5275,  0.5066, -0.7306,  1.1005,  0.4293,  0.5866,  0.8255,  1.2372,\n",
       "                       0.9379,  1.2798, -0.2567, -0.5586, -0.5343, -0.6842, -0.5157,  1.2418,\n",
       "                       0.1344,  0.8145, -0.0768,  2.2896,  1.3557, -0.7537,  0.2217,  0.2138,\n",
       "                       0.1862,  1.8267, -0.1477, -1.0606, -1.2362,  0.0777,  0.7473, -0.4000,\n",
       "                      -0.5854, -0.6587,  0.9069,  0.5211, -0.0660,  1.6332, -0.3462, -0.7333,\n",
       "                      -1.1437,  0.2524,  1.5219, -0.2012,  0.0825,  1.8109,  0.0483,  0.3039,\n",
       "                      -1.9780, -1.3015,  0.8588, -0.3836, -0.5829, -0.2961,  1.1298, -0.2335],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.mlp.1.weight',\n",
       "              tensor([ 0.3818, -0.6841,  0.9964,  0.5799, -0.6373,  0.8954, -0.8326, -0.6098,\n",
       "                       2.3523,  0.5505, -0.6550,  0.6059, -1.3162,  0.4687,  1.5755, -0.6629,\n",
       "                       1.1342, -0.7515, -0.8858, -0.6982,  1.1534,  0.7315,  0.5744,  0.6768,\n",
       "                       1.2795,  0.8057,  1.5119, -0.6374, -1.3498,  0.4728,  0.5702,  0.8566,\n",
       "                      -0.7598,  0.5332,  0.5238,  0.4265, -1.3676,  0.9268,  0.7896,  1.3113,\n",
       "                      -0.9617,  1.2679, -0.3724,  0.9933, -0.3913,  0.4633, -1.3892,  1.5377,\n",
       "                      -0.2790, -1.5151, -1.6184, -0.6093,  1.6131, -0.7407, -1.1047, -0.7937,\n",
       "                       0.7330, -1.4010, -0.4806,  0.2628, -0.8216, -0.4928, -0.2741, -0.3661,\n",
       "                       0.5483, -0.4701, -1.2735, -0.7331,  1.2777,  1.6311, -0.5180, -1.4165,\n",
       "                      -1.4106,  0.5047,  1.9395,  0.4989, -1.0150,  0.3920, -0.1916, -1.7921,\n",
       "                       0.6214, -2.0424,  0.6240, -1.7288, -1.3220, -0.5716, -0.6441,  1.2960,\n",
       "                      -0.6348,  0.6012, -0.7994,  0.8525, -0.5134,  0.4303,  0.3084, -1.2527,\n",
       "                      -1.0333,  0.9280,  1.3882,  0.8093, -0.4230,  1.0240,  0.9907,  1.3327,\n",
       "                       0.5356, -1.7733,  1.0326,  1.5464,  1.2832,  0.7247, -0.3714,  0.4888,\n",
       "                       1.2065,  0.8694, -1.9143, -1.3755,  0.6238,  1.3419,  0.4875, -1.0340,\n",
       "                       0.6182, -0.9274,  0.8983,  0.5713, -0.8575, -1.1125,  0.5318,  0.8703],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.mlp.1.bias',\n",
       "              tensor([-0.1147, -0.3500, -0.1952, -0.1779, -0.1569, -0.3020, -0.2922, -0.1830,\n",
       "                      -0.6129, -0.0456, -0.4390, -0.0977, -0.2140, -0.3254, -0.5804, -0.0443,\n",
       "                      -0.1537, -0.3723, -0.2429, -0.1638, -0.0838, -0.2551, -0.3290, -0.0657,\n",
       "                      -0.1864, -0.4299, -0.4101, -0.1820, -0.3048, -0.0343, -0.2337, -0.2393,\n",
       "                      -0.0514, -0.2981, -0.2963, -0.2191, -0.1404, -0.4804, -0.2058, -0.1359,\n",
       "                      -0.2292, -0.5466, -0.1662, -0.0945, -0.1011, -0.1963, -0.3738, -0.3718,\n",
       "                      -0.1655,  0.1510, -0.2485, -0.0450, -0.5877, -0.2482, -0.3596,  0.0080,\n",
       "                      -0.2482, -0.4817, -0.0445, -0.2551, -0.2221, -0.2820, -0.1577, -0.2546,\n",
       "                      -0.3418, -0.3495, -0.3927, -0.3945, -0.3803, -0.3776, -0.1864, -0.1536,\n",
       "                      -0.0534,  0.1288, -0.0897, -0.2804,  0.2027, -0.1409, -0.1571, -0.3890,\n",
       "                       0.1140,  0.0328, -0.2584, -0.4455, -0.2271, -0.0974, -0.3052, -0.0782,\n",
       "                      -0.3058, -0.0755, -0.2286, -0.2765, -0.2030, -0.1648, -0.1792, -0.1518,\n",
       "                      -0.1667, -0.2137, -0.4116, -0.3807, -0.0305, -0.3248, -0.5417, -0.2224,\n",
       "                      -0.3331, -0.1968, -0.2852, -0.2429, -0.3851, -0.2706, -0.0528, -0.1658,\n",
       "                      -0.1248, -0.4348, -0.3062, -0.0510, -0.3573, -0.5077, -0.2313, -0.0406,\n",
       "                      -0.1462,  0.0347, -0.5691, -0.3538, -0.0570, -0.0895, -0.0672, -0.1872],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.mlp.1.running_mean',\n",
       "              tensor([ 0.6945,  0.7272, -2.0104, -1.1175,  0.8209, -1.6104,  1.6944,  1.0709,\n",
       "                       2.8577,  0.0274, -0.0383,  0.7636, -0.6581,  0.3059,  1.0672,  0.1267,\n",
       "                       0.5963,  0.2927,  0.8730,  0.8380, -0.7477, -0.5105,  0.1601,  1.7139,\n",
       "                      -1.1259, -1.9115, -0.8709,  1.1343,  0.6265, -0.4642,  0.5236, -1.5851,\n",
       "                       0.5626,  1.7602,  0.2850,  0.6819,  0.8796, -1.5642, -0.8536, -0.1250,\n",
       "                      -0.8749, -0.0720, -0.6512,  1.5044,  1.5761,  2.6421, -0.5638, -1.8075,\n",
       "                       0.6614,  1.1458,  0.5010,  1.9802, -2.2992,  0.1261, -0.4842,  1.5773,\n",
       "                      -1.6758, -0.1326, -1.0511, -2.3841,  0.9161,  1.4998,  0.4825,  0.4715,\n",
       "                      -2.4435,  2.5582,  1.4897,  0.7678, -1.9746,  0.6710,  0.6978,  0.3667,\n",
       "                      -0.0169,  0.8725, -1.1008, -0.0313, -0.0457,  0.0932,  1.9861,  1.5515,\n",
       "                       1.3055,  0.6213, -0.7202,  0.9442, -0.9938, -0.7834,  1.3772, -0.0666,\n",
       "                       1.1918,  0.5556,  0.5242,  2.1557,  1.5529, -1.2477, -0.1504, -0.1104,\n",
       "                      -0.2564,  1.4935, -0.5657, -0.9706, -0.7042, -0.0875,  0.7074,  0.6108,\n",
       "                      -1.0662, -0.6860,  0.6065,  0.9794, -0.0922,  1.3349, -1.1730, -1.0722,\n",
       "                      -0.6242, -0.2825,  1.5316, -0.0961, -0.6264,  0.2748, -0.6871,  1.2845,\n",
       "                      -2.2467, -2.5764,  1.8658, -0.9987, -0.2851,  0.5981,  1.3379,  0.0174],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.mlp.1.running_var',\n",
       "              tensor([1.8455, 2.0181, 1.8228, 1.4259, 1.3716, 1.8749, 4.1950, 2.6043, 3.0265,\n",
       "                      1.6191, 2.3801, 1.9841, 2.7690, 1.7163, 3.5038, 2.1407, 1.4650, 1.2595,\n",
       "                      3.0333, 1.3524, 2.2335, 1.8541, 2.3934, 2.8388, 2.0187, 2.1554, 2.4797,\n",
       "                      3.2139, 9.1369, 4.2271, 1.9931, 3.1428, 2.1506, 1.9002, 2.0620, 1.3461,\n",
       "                      3.4126, 5.2352, 1.7242, 2.6254, 2.6512, 2.3784, 2.0826, 1.8997, 1.5983,\n",
       "                      2.3937, 3.3925, 3.7655, 2.3207, 2.0536, 2.8263, 2.0627, 2.9670, 1.6497,\n",
       "                      5.1217, 1.9000, 2.9313, 4.0406, 1.2731, 3.1455, 2.3426, 1.3312, 1.1396,\n",
       "                      3.0813, 1.5628, 1.3466, 3.3283, 2.1954, 4.0021, 2.8055, 2.9486, 3.3870,\n",
       "                      3.9077, 2.1816, 4.0920, 1.5625, 1.5621, 2.7245, 1.7324, 3.6679, 3.5992,\n",
       "                      8.4642, 1.9097, 4.4874, 2.4515, 1.6102, 4.3440, 4.0560, 3.3280, 1.1754,\n",
       "                      1.2772, 3.1258, 2.2486, 2.2928, 2.8151, 3.4557, 3.7743, 3.4020, 3.0774,\n",
       "                      1.9801, 2.1504, 2.2849, 3.1169, 3.2916, 1.3663, 2.2547, 2.2390, 3.3944,\n",
       "                      2.1127, 1.8166, 1.7749, 1.9886, 3.4403, 2.5596, 2.7210, 1.6711, 3.0226,\n",
       "                      2.1944, 1.1428, 3.3552, 2.8440, 1.1423, 3.1040, 2.7473, 1.6335, 2.3083,\n",
       "                      1.5293, 1.2977], device='cuda:0', dtype=torch.float64)),\n",
       "             ('temporal_encoder.mlp.1.num_batches_tracked',\n",
       "              tensor(15798, device='cuda:0')),\n",
       "             ('decoder.0.weight',\n",
       "              tensor([[-0.5126, -0.0464,  0.0587,  ..., -0.1332,  0.1173,  0.2555],\n",
       "                      [ 0.0684, -0.0443, -0.1468,  ..., -0.0734,  0.3150,  0.0869],\n",
       "                      [ 0.1578, -0.3193,  0.0587,  ..., -0.2501,  0.0047,  0.1020],\n",
       "                      ...,\n",
       "                      [-0.2449,  0.5421,  0.3398,  ...,  0.2010, -0.1827,  0.1737],\n",
       "                      [-0.0812,  0.2501, -0.0905,  ..., -0.0469, -0.0911,  0.0078],\n",
       "                      [ 0.1537,  0.1108, -0.2379,  ..., -0.1031, -0.0267,  0.0102]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('decoder.0.bias',\n",
       "              tensor([ 0.7810, -0.2995, -1.1471, -1.8770,  0.2964, -0.2405, -1.2477,  2.0300,\n",
       "                       0.7767, -0.8746,  0.3621, -1.8349,  0.1736, -0.0616, -1.5618,  0.5374,\n",
       "                      -0.7512, -1.4322, -0.8707, -0.3350, -1.8068,  0.3008,  0.0102,  1.0299,\n",
       "                      -0.6647,  1.8812, -2.6019, -1.2323,  0.1011,  0.4696,  0.7026,  0.7415,\n",
       "                      -2.6291,  1.3259, -0.4116,  0.6260, -0.7474, -0.5128,  1.1868,  1.1143,\n",
       "                       0.5885, -0.3329,  0.5224,  0.2610, -0.8908, -0.1042, -0.3150,  1.2493,\n",
       "                       0.5075, -0.1647,  0.5920, -1.2283, -0.0399,  1.3140, -1.3194,  0.4179,\n",
       "                       0.1119, -1.0523,  0.9121, -0.6946,  1.0209,  1.1034, -1.7325,  1.5184],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('decoder.1.weight',\n",
       "              tensor([ 1.2890, -0.9240,  0.4247,  1.0812, -1.1678,  0.5444, -1.0660,  0.5519,\n",
       "                      -0.7511, -1.0046, -0.5870, -1.2997,  0.6459, -1.0144, -0.7681, -0.4213,\n",
       "                       0.9128,  1.5174, -1.5995, -0.6636,  0.6156, -0.8060,  2.1034,  0.5230,\n",
       "                       2.3990, -0.4971,  0.3545, -0.7931,  0.9054,  0.9275, -0.5613, -1.2065,\n",
       "                       1.0439,  0.4979, -0.4922, -0.4689, -0.4889,  0.7624,  0.6155, -1.1331,\n",
       "                      -0.4923, -0.5225, -0.6473, -0.7253,  0.5234,  0.7244,  0.4579, -0.5793,\n",
       "                      -3.1508, -1.2588, -0.7502, -0.9792,  0.6403,  0.8364, -0.5151, -0.6480,\n",
       "                      -0.6599, -1.0422, -0.3367,  0.7448, -1.9125, -0.4226, -1.9295, -0.4693],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('decoder.1.bias',\n",
       "              tensor([-7.5557e-02, -1.3010e-01,  1.3089e-01, -2.8547e-01, -6.1598e-02,\n",
       "                       1.8928e-01, -6.2383e-02, -3.0486e-02,  9.8374e-02, -1.2180e-01,\n",
       "                       3.3505e-05, -5.1765e-02,  9.0077e-02, -4.0512e-01, -1.3666e-01,\n",
       "                       3.8415e-02, -8.7074e-02, -1.2661e-01,  2.0368e-01,  5.2869e-02,\n",
       "                       1.5094e-01, -1.9318e-02, -2.8504e-01, -1.7123e-01, -8.0282e-02,\n",
       "                      -8.1938e-02,  1.8140e-01, -1.2668e-01,  7.1976e-02, -2.4472e-02,\n",
       "                      -3.7416e-02, -1.6762e-01,  1.1161e-01, -2.9878e-02, -1.0600e-01,\n",
       "                       2.3526e-01,  2.2967e-02, -1.0046e-01,  1.0036e-01, -2.4628e-01,\n",
       "                       4.4857e-02,  6.0819e-02, -1.3262e-01, -1.2317e-01,  1.7179e-02,\n",
       "                       1.2764e-01, -1.7761e-02, -1.2142e-01, -1.0374e-01,  3.0898e-02,\n",
       "                      -1.4243e-02, -2.4662e-02,  5.2363e-02,  9.1273e-02,  9.4890e-02,\n",
       "                      -3.4192e-02, -1.6379e-01,  3.0584e-02, -7.2970e-02, -1.1315e-01,\n",
       "                      -1.1489e-01,  1.2419e-02,  9.9126e-02, -4.7103e-02], device='cuda:0',\n",
       "                     dtype=torch.float64)),\n",
       "             ('decoder.1.running_mean',\n",
       "              tensor([ 2.5608, -1.9190, -2.2089, -1.7912,  2.5365, -1.4764, -2.1136,  2.4969,\n",
       "                      -0.7007, -1.4671,  0.1218, -3.0325,  2.6965,  0.9083, -0.1802,  1.0299,\n",
       "                      -1.3199, -2.8692,  1.8169, -0.1521, -2.7822, -0.0233,  0.9861,  0.1234,\n",
       "                       2.5537,  1.9153, -2.5503, -0.2731,  0.7980, -0.9253,  0.7117,  1.1347,\n",
       "                      -3.0188, -0.4632,  1.2427,  0.2334,  0.2902, -0.1200,  1.0644,  2.7128,\n",
       "                      -0.4534, -0.0250,  0.5057,  1.3698, -0.3214,  2.8619, -1.1717,  2.3326,\n",
       "                       3.2881,  2.5805, -1.0575, -1.4819,  1.6267,  0.5299, -1.2848,  0.4513,\n",
       "                       1.3544, -1.3943,  1.3587, -0.3616,  3.2204,  1.8710, -1.9109,  2.2244],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('decoder.1.running_var',\n",
       "              tensor([ 9.9116,  8.8382,  4.4753,  5.6767, 10.7467,  7.6276, 10.5556,  6.5494,\n",
       "                       9.2662,  7.5834,  7.5081,  8.2679, 11.7512,  5.3055,  9.1519,  4.5580,\n",
       "                       8.1473, 14.6459, 20.3993,  6.3127, 11.2409,  7.9081, 12.2147,  6.3305,\n",
       "                      26.6245,  6.6927,  5.6363,  7.4036,  7.5662, 12.4902,  6.1296,  7.6101,\n",
       "                       7.0211,  5.3176,  5.8351,  6.0777,  5.6144,  6.8803,  7.4069,  9.7500,\n",
       "                       6.0960,  4.6945,  4.6065,  3.9921,  5.0760, 15.1321,  5.6380,  5.2151,\n",
       "                      22.9555,  7.2219,  7.2300,  9.7707,  5.9381,  7.3813,  4.6899,  6.4358,\n",
       "                       5.8512,  7.8560,  4.1610,  7.9979, 17.4677,  5.7477, 10.2688,  6.3647],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('decoder.1.num_batches_tracked', tensor(15798, device='cuda:0')),\n",
       "             ('decoder.3.weight',\n",
       "              tensor([[ 0.1474, -0.1938,  0.0388,  ..., -0.0421,  0.1866, -0.1050],\n",
       "                      [ 0.2311,  0.2803, -0.3202,  ...,  0.3218, -0.0117,  0.0782],\n",
       "                      [-0.1121, -0.2893, -0.0611,  ..., -0.0021,  0.0533,  0.0348],\n",
       "                      ...,\n",
       "                      [ 0.1285, -0.0545, -0.4774,  ..., -0.4291,  0.0438, -0.2284],\n",
       "                      [-0.1572, -0.0298,  0.0537,  ...,  0.1511,  0.3403, -0.1096],\n",
       "                      [ 0.1718,  0.0036, -0.3526,  ..., -0.2334, -0.1422,  0.3219]],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('decoder.3.bias',\n",
       "              tensor([ 0.8287,  0.9997, -0.7173,  0.2857,  1.2766,  2.2162, -0.8763,  0.8209,\n",
       "                       1.9586, -0.1592, -0.9503,  1.9715,  0.4740, -0.3617, -0.4312, -0.0803,\n",
       "                       1.0078, -0.3886, -3.5005, -0.8929,  0.9689,  0.7238,  0.9545, -1.2407,\n",
       "                      -0.0283,  1.0337, -1.3006,  1.0156, -0.9814, -1.5195, -0.2296, -1.6589],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('decoder.4.weight',\n",
       "              tensor([ 1.2411, -1.4368, -0.6929, -1.8452, -1.0289,  0.5414,  1.3014, -1.0202,\n",
       "                      -0.9659, -1.3651,  0.6644,  1.8345,  1.5519,  0.7575,  1.0771, -1.2675,\n",
       "                      -2.4049, -1.0888,  1.6489, -1.0360,  1.3211, -1.7677,  2.4384,  0.9002,\n",
       "                       1.4035,  1.0664,  1.8108, -0.6468, -1.0442, -0.9980, -1.2975,  0.9448],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('decoder.4.bias',\n",
       "              tensor([ 0.4910,  0.5069,  0.2795,  0.5042,  0.4031,  0.6186,  0.3751,  0.1075,\n",
       "                       0.4513,  0.3846,  0.6998,  0.3551,  0.4914,  0.3012,  0.1659,  0.4658,\n",
       "                       0.4126,  0.3241,  0.1631,  0.2665,  0.3116,  0.5004,  0.3714,  0.4986,\n",
       "                       0.2969,  0.4486,  0.5026,  0.4595,  0.4099,  0.4370,  0.3172, -0.0029],\n",
       "                     device='cuda:0', dtype=torch.float64)),\n",
       "             ('decoder.4.running_mean',\n",
       "              tensor([ 3.1314e-01,  1.7650e+00, -1.3505e+00,  8.9606e-01,  1.6629e+00,\n",
       "                       1.5210e+00, -1.7003e+00,  3.8221e-01,  2.5319e+00,  4.9793e-01,\n",
       "                      -1.8782e+00,  2.0268e+00, -7.3277e-04, -1.0663e+00, -8.9648e-01,\n",
       "                      -3.3455e-01,  1.5967e+00, -3.0189e-01, -3.4244e+00, -1.0604e+00,\n",
       "                       9.7095e-01,  4.8200e-01,  8.0638e-01, -1.9642e+00, -1.5302e-01,\n",
       "                       1.2236e+00, -1.1346e+00,  2.0317e+00, -3.9053e-02, -2.0585e+00,\n",
       "                      -1.0773e-01, -1.7557e+00], device='cuda:0', dtype=torch.float64)),\n",
       "             ('decoder.4.running_var',\n",
       "              tensor([0.5121, 1.0289, 0.8556, 0.6026, 0.8638, 0.4131, 1.0105, 0.7408, 0.7683,\n",
       "                      0.8133, 0.7317, 0.7679, 1.5502, 0.5446, 0.4974, 0.4148, 1.4009, 0.5713,\n",
       "                      0.9953, 1.0026, 0.9035, 1.7553, 1.1027, 0.6672, 0.6128, 0.6008, 1.1004,\n",
       "                      0.4339, 0.4854, 0.6612, 1.2524, 0.7608], device='cuda:0',\n",
       "                     dtype=torch.float64)),\n",
       "             ('decoder.4.num_batches_tracked', tensor(15798, device='cuda:0')),\n",
       "             ('decoder.6.weight',\n",
       "              tensor([[ 1.4045e-01, -4.0061e-01,  1.9122e-01, -4.7481e-01,  2.8985e-01,\n",
       "                        3.7151e-01, -1.9456e-01,  3.4472e-02,  2.5318e-01, -2.9201e-01,\n",
       "                       -7.9767e-01,  4.8677e-01, -2.7020e-01,  5.2563e-02, -2.3272e-01,\n",
       "                        6.4419e-02,  3.4431e-01, -4.2074e-01, -1.0472e-01,  4.5447e-01,\n",
       "                        2.9280e-01,  2.9154e-01, -5.2311e-01,  4.9430e-01, -4.8712e-02,\n",
       "                       -6.6631e-05, -3.4586e-01, -5.0805e-01,  5.1929e-02, -1.0374e-01,\n",
       "                        2.7919e-01, -4.1266e-01],\n",
       "                      [ 2.2773e-01, -2.6934e-01,  3.2204e-01, -2.3943e-01,  4.1638e-01,\n",
       "                        4.4071e-01, -1.4339e-01,  1.1734e-02,  3.5135e-01, -2.9087e-01,\n",
       "                       -4.8414e-01,  2.6598e-01, -1.7946e-01,  6.4173e-02, -3.1035e-01,\n",
       "                        1.8055e-01,  4.7273e-01,  7.0706e-02,  8.2895e-02, -1.4625e-01,\n",
       "                        3.9121e-01,  4.4369e-01, -3.6927e-01,  4.0014e-01, -6.7737e-02,\n",
       "                       -3.7173e-01, -5.8919e-02, -6.6362e-02,  5.1671e-02, -4.0844e-02,\n",
       "                        6.3692e-02, -1.8985e-01],\n",
       "                      [ 9.3659e-02, -1.5975e-01,  2.0273e-01, -2.7110e-01,  1.7659e-01,\n",
       "                        4.2924e-01, -5.1813e-02,  1.0977e-01,  4.0083e-01, -2.7796e-01,\n",
       "                       -5.5379e-02,  1.9841e-01, -6.2233e-02,  2.0493e-01, -2.8178e-01,\n",
       "                        2.5022e-01,  3.9220e-01, -9.2615e-02,  3.2505e-01,  2.1250e-01,\n",
       "                       -5.5432e-02,  3.6048e-01, -4.6813e-01,  3.9935e-01, -3.0210e-02,\n",
       "                       -3.6936e-02, -6.3598e-02,  2.7716e-01,  2.2253e-01,  4.2731e-01,\n",
       "                        6.6689e-01, -1.3929e-01],\n",
       "                      [-2.3118e-01, -4.3191e-01, -4.8809e-02, -2.1401e-01,  2.7484e-01,\n",
       "                        5.3391e-01, -7.3786e-01, -3.0950e-01, -1.7645e-02, -3.4701e-01,\n",
       "                       -9.6872e-01, -2.1638e-01, -7.7554e-01, -3.2576e-01, -4.4133e-01,\n",
       "                       -1.8062e-01,  2.3559e-01,  3.9195e-02,  5.6079e-01,  6.9451e-01,\n",
       "                       -3.3829e-01, -1.2754e-01, -5.4986e-01, -7.0120e-01, -7.5081e-02,\n",
       "                       -3.5778e-01, -2.0351e-01, -4.8565e-01, -3.4444e-01,  2.1290e-01,\n",
       "                        5.3033e-02, -2.7815e-02],\n",
       "                      [ 4.2641e-01,  2.6570e-01,  2.3261e-02,  6.2663e-01, -2.2841e-02,\n",
       "                       -8.9049e-01, -3.1075e-01,  2.9384e-01, -1.0331e-01, -5.3801e-01,\n",
       "                       -2.8791e-01, -1.1145e-01,  8.7055e-01,  4.8335e-01, -8.3537e-01,\n",
       "                       -2.8967e-01, -1.3450e-01, -4.5170e-01,  1.6472e-02, -2.5591e-01,\n",
       "                        1.0928e-01, -4.9387e-01, -2.3284e-01,  1.8590e-02, -4.4043e-02,\n",
       "                       -1.1220e-01, -7.6200e-03, -3.3265e-02, -4.9536e-01,  6.0614e-01,\n",
       "                       -2.9743e-01,  5.8474e-01],\n",
       "                      [ 3.1743e-01,  2.0671e-01,  5.7062e-01, -1.5441e-01, -1.5943e-01,\n",
       "                        8.8487e-01,  4.3900e-01,  5.6456e-01, -4.4012e-01,  4.2476e-01,\n",
       "                        5.5848e-01,  1.0838e-01,  2.4451e-01, -2.2005e-01, -2.2887e-01,\n",
       "                       -2.8011e-01, -4.1079e-01, -1.7148e-01,  1.7971e-01, -6.1892e-01,\n",
       "                       -7.2986e-02,  3.7898e-01,  2.9719e-01, -1.5598e-01, -3.7056e-01,\n",
       "                        1.3158e-01, -4.5791e-01, -7.1992e-01, -3.3474e-01,  2.2129e-01,\n",
       "                       -2.0731e-01,  2.0986e-01],\n",
       "                      [ 3.4896e-01,  1.4003e-01,  4.2070e-01,  6.3108e-01,  2.7294e-01,\n",
       "                        1.1410e+00, -1.1412e-01,  1.8180e-01, -7.9793e-02, -6.6321e-01,\n",
       "                        2.8967e-01, -2.1813e-01,  5.5279e-02,  1.7911e-01,  2.4254e-01,\n",
       "                        4.0642e-01, -4.6441e-01, -7.0157e-01,  3.2837e-01, -3.3334e-01,\n",
       "                       -2.6176e-01, -1.9530e-01,  2.5584e-01, -6.6037e-02, -4.0046e-01,\n",
       "                       -5.1726e-01, -4.8213e-01, -2.6947e-01,  2.7928e-01, -2.6445e-01,\n",
       "                       -4.4624e-01, -2.9773e-01],\n",
       "                      [-9.4395e-02,  5.6649e-01, -5.0802e-01,  1.8561e-01, -7.1196e-01,\n",
       "                        6.1141e-01, -1.8233e-01,  2.2080e-01,  5.0306e-02,  2.4810e-01,\n",
       "                        6.3185e-01, -7.8151e-02,  3.4052e-01, -5.0296e-01,  5.1640e-01,\n",
       "                       -3.3542e-01,  4.6276e-01, -3.0321e-01,  1.2967e-01, -6.4286e-01,\n",
       "                       -2.4644e-01, -5.1672e-01, -3.6133e-01,  7.8209e-01,  6.1344e-01,\n",
       "                        5.4585e-01, -3.1539e-02,  2.9781e-01, -5.7004e-02, -4.1608e-01,\n",
       "                       -3.4804e-01, -7.9340e-03],\n",
       "                      [ 5.4722e-02, -1.6142e-01,  1.9623e-01, -1.5710e-02, -5.8041e-01,\n",
       "                        5.0778e-01,  5.6756e-01, -5.8665e-01,  8.7072e-01,  2.0168e-01,\n",
       "                        3.7345e-01, -3.4000e-01,  6.1056e-01, -8.8887e-02, -1.3273e-01,\n",
       "                       -1.3304e-01, -1.8039e-01, -2.6577e-01, -3.9195e-01, -1.3331e-01,\n",
       "                       -9.2658e-02,  2.1032e-01, -7.8401e-02, -3.2911e-01,  5.8298e-01,\n",
       "                        3.5431e-01,  3.8314e-01,  3.7315e-01,  4.8344e-01,  1.9367e-01,\n",
       "                       -6.1628e-01, -2.7302e-02],\n",
       "                      [-3.7800e-01,  5.0279e-01, -4.3869e-01,  2.4895e-01,  2.9838e-01,\n",
       "                       -5.6411e-01,  8.8943e-02, -2.4769e-01,  5.7881e-01,  3.4197e-01,\n",
       "                        4.4654e-01, -3.8968e-01, -1.3949e-02, -9.4352e-01, -3.1130e-01,\n",
       "                       -2.4164e-01, -1.3608e-01, -7.6691e-01, -5.5861e-01,  1.2100e-01,\n",
       "                       -2.7472e-01,  4.7011e-02,  2.2282e-01,  7.9410e-01,  9.5038e-02,\n",
       "                       -7.8244e-01,  5.8680e-01,  3.6860e-01,  7.5993e-02, -4.4007e-01,\n",
       "                        1.2486e-01,  2.0193e-01],\n",
       "                      [ 4.5158e-01, -1.6383e-02, -2.6716e-01, -4.5099e-01, -1.0724e+00,\n",
       "                       -8.4119e-01, -2.9055e-01, -8.9973e-03,  7.8597e-01, -2.0408e-01,\n",
       "                        2.5937e-01, -8.3971e-01,  7.5186e-01, -1.3013e-01, -3.2316e-01,\n",
       "                       -2.0661e-01, -1.8879e-01, -1.0847e+00,  5.4528e-01,  8.3051e-01,\n",
       "                        7.6942e-01, -1.5967e-01,  6.1481e-02,  8.6804e-01, -2.8378e-02,\n",
       "                       -5.4295e-01, -1.4062e-01, -1.3748e-01,  2.0674e-01, -1.0689e+00,\n",
       "                       -6.6871e-02, -6.6894e-01],\n",
       "                      [ 7.1458e-01,  7.8795e-01, -1.9789e-03, -1.8738e-01,  2.6899e-01,\n",
       "                       -7.3808e-01,  5.6406e-02,  4.3098e-02, -5.7948e-01, -3.2056e-01,\n",
       "                        5.8219e-04,  8.5300e-02, -1.2482e-01, -3.9080e-01,  1.8092e-01,\n",
       "                        6.5229e-01, -8.6677e-02,  4.2429e-01, -5.6916e-02, -4.2982e-01,\n",
       "                       -1.9283e-01, -6.1851e-02, -1.0537e-01,  9.5236e-03, -5.3188e-01,\n",
       "                       -1.4501e-01,  8.2280e-02, -5.5877e-01,  2.9653e-02,  3.6160e-01,\n",
       "                       -4.5792e-01, -5.6624e-01],\n",
       "                      [-4.7621e-01,  2.7574e-01,  3.2693e-01, -2.3757e-01, -4.1712e-01,\n",
       "                       -6.2518e-02,  1.6981e-01, -5.4675e-01, -2.3641e-01, -3.6455e-02,\n",
       "                       -8.8883e-01,  4.4427e-01,  2.2151e-01, -5.5489e-01, -2.2840e-01,\n",
       "                       -8.2556e-02, -4.7798e-01,  6.8403e-01,  7.7299e-02, -4.1248e-01,\n",
       "                        4.3432e-01, -3.1298e-01,  3.0927e-02, -5.9734e-01, -3.8083e-01,\n",
       "                        3.5464e-02,  2.2518e-01,  4.8117e-01,  2.7617e-01, -7.3172e-01,\n",
       "                        7.5713e-01,  2.0742e-01],\n",
       "                      [-3.6393e-01, -1.6624e-02, -8.0457e-01, -3.0419e-01, -4.7595e-01,\n",
       "                       -1.0096e+00, -3.3711e-01,  4.8770e-02, -1.2756e-01, -3.0829e-01,\n",
       "                       -1.0641e+00, -4.2629e-01, -2.1371e-01,  8.3405e-01,  6.9198e-01,\n",
       "                       -3.5091e-01, -4.0732e-01,  1.6502e-01, -3.8045e-01, -3.6482e-01,\n",
       "                        1.2221e-01,  2.5778e-02,  3.1696e-03, -3.8457e-01, -4.4987e-02,\n",
       "                       -1.9349e-01, -6.1011e-01, -9.7093e-01, -1.8132e-01, -3.3126e-01,\n",
       "                        6.1618e-01, -8.5609e-02],\n",
       "                      [-4.8760e-01, -8.5199e-01,  2.6360e-01,  3.7894e-01, -4.7543e-01,\n",
       "                       -3.2269e-01, -8.2506e-01, -5.3741e-01, -4.4049e-01,  3.2570e-02,\n",
       "                       -5.3771e-01,  1.1605e-01, -4.8513e-01, -1.1059e+00,  2.8426e-03,\n",
       "                        3.0360e-01,  4.2592e-01,  5.4279e-02,  8.4482e-02, -6.2471e-01,\n",
       "                       -3.3252e-01,  4.2190e-02,  2.5100e-01, -1.0485e+00, -6.5412e-01,\n",
       "                        4.3861e-02,  4.4111e-01, -4.3221e-01,  1.3969e-01,  1.1134e-01,\n",
       "                       -2.4648e-01, -3.3303e-01],\n",
       "                      [ 5.8382e-01, -4.5149e-01, -2.7512e-01,  2.8827e-01, -4.8800e-01,\n",
       "                       -1.6679e-01, -1.6123e+00, -3.3946e-01, -1.4896e-01, -4.1038e-01,\n",
       "                       -1.2203e+00,  1.9451e-01, -1.9489e-01, -6.9939e-01,  9.4025e-02,\n",
       "                        8.9007e-03,  7.1242e-01,  5.0522e-01, -2.2695e-01,  5.9348e-02,\n",
       "                        1.8136e-01, -6.8623e-01,  4.9776e-01, -3.2245e-01, -3.3558e-01,\n",
       "                       -2.6826e-01, -1.6376e-01, -4.7709e-01,  5.9561e-01, -7.0140e-01,\n",
       "                        1.2412e-01,  2.0745e-02],\n",
       "                      [ 4.9585e-01, -1.2432e+00,  2.3971e-01,  1.1114e-01,  3.1805e-02,\n",
       "                       -4.3469e-01,  1.6246e-01, -5.1602e-02,  1.3194e-01, -1.4280e-01,\n",
       "                        3.7917e-01, -8.7984e-02, -6.9376e-01,  1.0148e-01, -1.5754e-01,\n",
       "                        8.9232e-01,  8.7131e-03,  4.2491e-01, -1.7465e-01,  3.4085e-01,\n",
       "                       -2.8432e-01,  2.2049e-01,  1.7288e-01, -1.8440e-01,  5.7252e-01,\n",
       "                        4.0984e-01, -3.9203e-01, -3.9199e-01, -7.7729e-01, -4.6424e-02,\n",
       "                       -2.6429e-02, -1.3976e-01],\n",
       "                      [-6.3353e-02, -4.5502e-01, -8.8622e-01,  1.2911e-01,  7.5249e-02,\n",
       "                       -3.1039e-01, -2.9024e-01,  3.4031e-01,  1.2189e-01,  3.3991e-01,\n",
       "                       -1.1019e+00, -1.2149e-01, -3.6154e-01, -7.1254e-01,  4.3580e-01,\n",
       "                        5.3850e-01, -1.8824e-01,  6.3182e-01,  1.6444e-01,  4.6183e-02,\n",
       "                       -3.6026e-01,  1.7765e-01, -2.8539e-01,  2.6526e-01, -3.2118e-01,\n",
       "                       -1.7374e-01, -1.2340e-01, -7.5752e-01,  5.0944e-02,  4.9667e-01,\n",
       "                       -3.2182e-01,  2.0346e-01],\n",
       "                      [-4.1469e-01,  1.4696e-01, -5.3675e-01, -6.2666e-01,  1.9077e-01,\n",
       "                       -7.6188e-01, -9.6560e-01,  4.1865e-01, -6.7594e-02,  1.5493e-01,\n",
       "                       -1.1368e+00,  4.5193e-01,  7.0633e-02,  2.4833e-02,  3.0538e-02,\n",
       "                        3.5656e-01, -1.9554e-01, -6.4405e-01,  7.8634e-01,  1.8113e-01,\n",
       "                       -5.7645e-01, -9.6380e-01,  2.5798e-01, -2.1287e-01, -2.5502e-01,\n",
       "                       -4.2257e-01,  2.5147e-01,  4.4695e-01,  2.0363e-01, -5.1121e-01,\n",
       "                        2.2779e-01,  2.3655e-01]], device='cuda:0', dtype=torch.float64)),\n",
       "             ('decoder.6.bias',\n",
       "              tensor([-0.9478, -0.2146, -1.7100,  1.3668,  0.2860, -0.6811, -0.5190,  0.1123,\n",
       "                       1.7517,  0.7093, -0.6103, -0.2959, -0.2960,  2.5854, -0.1249, -2.4169,\n",
       "                      -0.9678, -0.3047, -1.0229], device='cuda:0', dtype=torch.float64))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da4cdaa-cbbd-49b6-8a27-9bb3aceac9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_dict['temporal_encoder.position_enc.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e766de31-810d-4197-bc27-c4e2e25561ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dLtae(in_channels = js['in_channels'], n_head = js['n_head'], d_k= js['d_k'], n_neurons=js['n_neurons'], dropout=js['dropout'], d_model= js['d_model'],\n",
    "                 mlp = js['mlp4'], T =js['T'], len_max_seq = js['len_max_seq'], \n",
    "              positions=None, return_att=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8528eb59-c44e-4515-b69e-49f3f0d4855e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb66d9f2-0554-4547-ab7c-2f9e0c7c6748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dLtae(\n",
       "  (temporal_encoder): LTAE(\n",
       "    (inconv): Sequential(\n",
       "      (0): Conv1d(10, 256, kernel_size=(1,), stride=(1,))\n",
       "      (1): LayerNorm((256, 33), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (position_enc): Embedding(34, 256)\n",
       "    (inlayernorm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "    (outlayernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (attention_heads): MultiHeadAttention(\n",
       "      (fc1_k): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (attention): ScaledDotProductAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=2)\n",
       "      )\n",
       "    )\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=19, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2161d2cf-0b4e-498a-8735-da1570520d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = '../../../results/ltae/trials/Seed_0/model.pth.tar'\n",
    "\n",
    "# model.load_state_dict(torch.load(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b868824b-0cb2-4ef6-899b-59ed599f50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write a function to plot the curves\n",
    "def plot_curve(data):\n",
    "    data = json.load(open(data))\n",
    "    \n",
    "    epoch =range(1, len(data)+1)\n",
    "    # Loss\n",
    "    train_loss = [data[str(i)]['train_loss'] for i in epoch]\n",
    "    val_loss = [data[str(i)]['val_loss'] for i in epoch]\n",
    "    # Accuracy\n",
    "    train_accuracy = [data[str(i)]['train_accuracy'] for i in epoch]\n",
    "    val_accuracy = [data[str(i)]['val_accuracy'] for i in epoch]\n",
    "    # IOU\n",
    "    train_IoU = [data[str(i)]['train_IoU'] for i in epoch]\n",
    "    val_IoU = [data[str(i)]['val_IoU'] for i in epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e22c9fe-bd63-47f3-ab11-e2fca1c0fe8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def date_positions(gfdate_path):\n",
    "    with open(gfdate_path, \"r\") as f:\n",
    "        out_date_list = f.readlines()\n",
    "    out_date_list = [x.strip() for x in out_date_list]\n",
    "    out_date_list = [datetime.datetime.strptime(x, \"%Y%m%d\").timetuple().tm_yday for x in out_date_list]\n",
    "    string_date_list = [x for x in out_date_list]\n",
    "    return string_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba89faf-2ff1-4f60-a5e8-e0de805f4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = time.time()\n",
    "# t = date_positions(\"dates.txt\")\n",
    "# s = date_positions(\"dates.txt\")\n",
    "# print(t)\n",
    "# print(s)\n",
    "# print(\"time: \", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4bae7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0354f6-6fab-4408-9bf8-049de825ae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed value:  9\n",
      "Read set ids completed: 0.0015230178833007812 second\n"
     ]
    }
   ],
   "source": [
    "def generate_ids():\n",
    "    \"\"\"\n",
    "    Descr: \n",
    "        Aim: To write and returns the partition (Train, Validation and Test) ids \n",
    "        with respect to the grid split index (range 1 - 100)\n",
    "        \n",
    "        - A random seed value is set within a random intger 1-10,\n",
    "        - the set is spltted into 80:10:10,\n",
    "        - save into a text file with the seed value used\n",
    "    \"\"\"\n",
    "    # set a random seed value within the range 1 -10 \n",
    "    start_time = time.time()\n",
    "    seed_value = 9\n",
    "    # seed_value = np.random.randint(0,10)\n",
    "    np.random.seed(seed_value)\n",
    "    # # block id range 1 - 100 (splitted grid)\n",
    "    block_range = np.arange(1, 101)\n",
    "\n",
    "    # Train, Validation and Test\n",
    "    random.shuffle(block_range)\n",
    "    train_id = block_range[:60] # 60%\n",
    "    val_id = block_range[60:80] # 20%\n",
    "    test_id = block_range[80:] # 20%\n",
    "    print(\"Seed value: \", seed_value)\n",
    "    \n",
    "    if not os.path.exists(\"./ids/train_val_eval_seed_\" + str(seed_value)+\".txt\"):\n",
    "        with open(\"./ids/train_val_eval_seed_\" + str(seed_value)+\".txt\", \"w\") as f:\n",
    "            f.write(\"Training: \" + str(list(train_id)) + \"\\n\")\n",
    "            f.write(\"Validation: \" + str(list(val_id)) + \"\\n\")\n",
    "            f.write(\"Testing: \" + str(list(test_id)) + \"\\n\")\n",
    "            f.close()\n",
    "    print('Read set ids completed: %s second' % (time.time() - start_time))\n",
    "generate_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "276ef82d-965b-4daa-bb1d-29d4d017d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ids(seed_value):\n",
    "    \"\"\"\n",
    "    Read ids from file\n",
    "    \"\"\"\n",
    "    assert seed_value >= 0 and seed_value <= 10\n",
    "    \n",
    "    with open(\"./ids/train_val_eval_seed_\" + str(seed_value)+\".txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        Train_ids = eval(lines[0].split(\":\")[1])\n",
    "        Val_ids = eval(lines[1].split(\":\")[1])\n",
    "        test_ids = eval(lines[2].split(\":\")[1])\n",
    "    return Train_ids, Val_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09eda6b1-6b84-4958-bedc-d1d7b09ab679",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_ids, Val_ids, test_ids = read_ids(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c54f52d-491e-4370-a655-fbe313d4a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = Val_ids + test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5829fcc8-8d68-48c8-a782-f14ca40a88e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fec2129-501a-494e-9391-0082163b4803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80, 39, 18, 65, 81, 8, 94, 76, 93, 32]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cfa68ac-d630-4be7-9663-86f3e22e37dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[79, 82, 34, 30, 46, 20, 9, 7, 23, 45, 80, 39, 18, 65, 81, 8, 94, 76, 93, 32]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0d45cfe-a8f6-4922-9964-ce63bed9c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(source_sits, target_sits, case):\n",
    "    \"\"\"\n",
    "    Descr: Compute mean and std for each channel\n",
    "    Input: both SITS dataset(.npz) paths\n",
    "            Case[1 - 3]:\n",
    "            1 - concatenate both dataset, while 2 & 3 rep source and target respectively\n",
    "    The data(from N,LxD) is reshaped into (N,D,L);\n",
    "        where N - pixel, D - Bands (10), L - Time (33)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # case = 1: both, case = 2: target, case = 3: target\n",
    "    if case == 1:\n",
    "        sits = [source_sits, target_sits]\n",
    "    elif case == 2:\n",
    "        sits = source_sits\n",
    "    elif case == 3:\n",
    "        sits = target_sits\n",
    "    else:\n",
    "        print('Select case between 1-3')\n",
    "        return None\n",
    "    \n",
    "    # if sits is a list, then it's a list of paths\n",
    "    if isinstance(sits, list):\n",
    "        # load data\n",
    "        X_source = np.load(sits[0])['X']\n",
    "        X_target = np.load(sits[1])['X']\n",
    "        # concatenate the data\n",
    "        X = np.concatenate((X_source, X_target), axis=0)\n",
    "    # if sits is a string, then it's a path\n",
    "    else: \n",
    "        with np.load(sits) as data:\n",
    "            X = data['X']\n",
    "\n",
    "    X = X.reshape(X.shape[0], n_channel, int(X.shape[1]/n_channel))\n",
    "    # compute mean and std\n",
    "    X_mean = np.mean(X, axis=(0,2))\n",
    "    X_std = np.std(X, axis=(0,2))\n",
    "    print('mean shape: ', X_mean.shape)\n",
    "    print('std shape: ', X_std.shape)\n",
    "    # save X_mean and X_std sepearately for sits as txt file\n",
    "    np.savetxt(os.path.join('mean_'+ str(case) +'.txt'), X_mean)\n",
    "    np.savetxt(os.path.join('std_'+ str(case) +'.txt'), X_std)\n",
    "\n",
    "# for i in [1,2,3]:\n",
    "#     start_time = time.time()\n",
    "#     source_path = \"../../../data/theiaL2A_zip_img/output/2018/2018_SITS_data.npz\"\n",
    "#     target_path = \"../../../data/theiaL2A_zip_img/output/2019/2019_SITS_data.npz\"\n",
    "#     compute_mean_std(source_path, target_path, i)\n",
    "#     print(\"run time: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d277504e-263a-44ba-81b3-ecc67ccf65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_stdv2(sits, domain='source'):\n",
    "    \"\"\"\n",
    "    Descr: Compute mean and std for each channel\n",
    "    Input: both SITS dataset(.npz) paths\n",
    "    The data(from N,LxD) is reshaped into (N,D,L);\n",
    "        where N - pixel, D - Bands (10), L - Time (33)\n",
    "    \"\"\"\n",
    "    with np.load(sits) as data:\n",
    "            X = data['X']\n",
    "\n",
    "    X = X.reshape(X.shape[0], n_channel, int(X.shape[1]/n_channel))\n",
    "    # compute mean and std\n",
    "    X_mean = np.mean(X, axis=(0,2))\n",
    "    X_std = np.std(X, axis=(0,2))\n",
    "    print('mean shape: ', X_mean.shape)\n",
    "    print('std shape: ', X_std.shape)\n",
    "    # save X_mean and X_std sepearately for sits as txt file\n",
    "    np.savetxt(os.path.join('./mean_std/', domain + '_mean.txt'), X_mean)\n",
    "    np.savetxt(os.path.join('./mean_std/', domain + '_std.txt'), X_std)\n",
    "\n",
    "source_path = '../../../data/theiaL2A_zip_img/output/2018/2018_SITS_subset_data.npz'\n",
    "target_path = '../../../data/theiaL2A_zip_img/output/2019/2019_SITS_subset_data.npz'\n",
    "# compute_mean_stdv2(source_path, 'source')\n",
    "# compute_mean_stdv2(target_path, domain = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d4055b3-c150-4215-9576-9569a415ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SITSDatav2(data.Dataset):\n",
    "    def __init__(self, sits, seed, partition='train', transform=None):\n",
    "        \n",
    "        self.sits = sits\n",
    "        self.seed = seed\n",
    "        self.transform = transform\n",
    "        \n",
    "        # get partition ids using the read_id() func\n",
    "        start_time = time.time()\n",
    "        self.train_ids, self.val_ids, self.test_ids = read_ids(self.seed)\n",
    "        print(\"read ids completed: %s second\" % (time.time() - start_time))\n",
    "\n",
    "        # select partition\n",
    "        if partition == 'train':\n",
    "            self.ids = self.train_ids\n",
    "        elif partition == 'val':\n",
    "            self.ids = self.val_ids\n",
    "        elif partition == 'test':\n",
    "            self.ids = self.test_ids\n",
    "        else:\n",
    "            raise ValueError('Invalid partition: {}'.format(partition))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        print('reading files....')\n",
    "        X, y, block_ids = load_npz(self.sits)\n",
    "        print(\"load npz: %s seconds\" % (time.time() - start_time))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        y = np.unique(y, return_inverse=True)[1]\n",
    "        print(\"reassigning %s seconds\" % (time.time() - start_time))\n",
    "        \n",
    "        # concatenate the data\n",
    "        start_time = time.time()\n",
    "        data_ = np.concatenate((X, y[:, None], block_ids[:, None]), axis=1)\n",
    "        print(\"Concatenating completed: %s seconds\" % (time.time() - start_time))\n",
    "\n",
    "        # filter by block_id\n",
    "        start_time = time.time()\n",
    "        data_ = data_[np.isin(data_[:, -1], self.ids)]\n",
    "        print(\"filtering ids completed: %s seconds\" % (time.time() - start_time))\n",
    "        \n",
    "        self.X_ = data_[:, :-2]\n",
    "        self.y_ = data_[:, -2]                          \n",
    "        \n",
    "        del X\n",
    "        del y\n",
    "        del block_ids\n",
    "        del data_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_time = time.time()\n",
    "        self.X = self.X_[idx]\n",
    "        self.y = self.y_[idx]\n",
    "        print(\"getting data: %s seconds\" % ((time.time() - start_time)*100))\n",
    "\n",
    "        start_time = time.time()\n",
    "        self.X = np.array(self.X).astype('float32')\n",
    "        self.y = np.array(self.y).astype('float32')\n",
    "        print(\"conversion: %s seconds\" % ((time.time() - start_time)*100))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.X = self.X.reshape(int(self.X.shape[0]/n_channel), n_channel)\n",
    "        print(\"reshape data: %s seconds\" % ((time.time() - start_time)*100))\n",
    "\n",
    "        # transform\n",
    "        start_time = time.time()\n",
    "        if self.transform:\n",
    "            self.X = self.transform(self.X)\n",
    "        print(\"transform data: %s seconds\" % ((time.time() - start_time)*100))\n",
    "        print(self.X.shape)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        torch_x = torch.from_numpy(self.X)\n",
    "        torch_y = torch.from_numpy(self.y)\n",
    "        print(\"tensor: %s seconds\" % ((time.time() - start_time)*100))\n",
    "        \n",
    "        return torch_x, torch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8190c2ef-d5ca-4ace-8b0b-34c6d4dc3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "class standardize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return (sample - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9aa04b1-cd97-4f62-8bef-cb40c4c0b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ids completed: 0.001961231231689453 second\n",
      "reading files....\n",
      "load npz: 7.151129961013794 seconds\n",
      "reassigning 0.0646812915802002 seconds\n",
      "Concatenating completed: 1.7340800762176514 seconds\n",
      "filtering ids completed: 1.6481618881225586 seconds\n"
     ]
    }
   ],
   "source": [
    "mean = np.loadtxt('./mean_std/source_mean.txt')\n",
    "std = np.loadtxt('./mean_std/source_std.txt')\n",
    "seed = 0 \n",
    "transform = transforms.Compose([standardize(mean, std)])\n",
    "\n",
    "# paths\n",
    "source_path = '../../../data/theiaL2A_zip_img/output/2018/2018_SITS_subset_data.npz'\n",
    "# target_path = '../../../data/theiaL2A_zip_img/output/2019/2019_SITS_subset_data.npz'\n",
    "\n",
    "train_dataset = SITSDatav2(source_path, seed, partition='train', transform=transform)\n",
    "# val_dataset = SITSDatav2(source_path, seed, partition='val', transform=transform)\n",
    "# test_dataset = SITSDatav2(source_path, seed, partition='test', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcd1385b-6909-4257-b631-68d733493857",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = '../../../data/theiaL2A_zip_img/output/2018/2018_SITS_subset_data.npz'\n",
    "X, y, _ = load_npz(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8748f0a9-610b-4951-bb7b-594165d7d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_ = {0:1, \n",
    "#         1:2, \n",
    "#         2:3, \n",
    "#         3:4, \n",
    "#         4:5, \n",
    "#         5:6, \n",
    "#         6:7,\n",
    "#         7:8,\n",
    "#         8:9,\n",
    "#         9:10,\n",
    "#         10:12,\n",
    "#         11:13,\n",
    "#         12:14,\n",
    "#         13:15,\n",
    "#         14:16,\n",
    "#         15:17,\n",
    "#         16:18,\n",
    "#         17:19,\n",
    "#         18:23}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7ba0963-5865-4c59-9067-044b9fbfdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_uniq = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49b786d5-7808-4a39-beab-4ff547a5dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_revs_uniq = np.unique(np.unique(y, return_inverse=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6caadcdd-e26e-4ab0-ae24-9ee7a1dc462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 2: 1,\n",
       " 3: 2,\n",
       " 4: 3,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 6,\n",
       " 8: 7,\n",
       " 9: 8,\n",
       " 10: 9,\n",
       " 12: 10,\n",
       " 13: 11,\n",
       " 14: 12,\n",
       " 15: 13,\n",
       " 16: 14,\n",
       " 17: 15,\n",
       " 18: 16,\n",
       " 19: 17,\n",
       " 23: 18}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict__ = dict(zip(y_uniq, y_revs_uniq))\n",
    "dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba679ae1-c74c-4f5e-b1ce-9458340153e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = [dict__[i] for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac64ba86-8c6b-420a-ab89-75c4e9333788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6b2cb17-21dd-4ba1-9d81-57415709abe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop time 2.462660789489746\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "y = np.unique(y, return_inverse=True)[1]\n",
    "\n",
    "y_train_mapped = np.zeros(y.shape)\n",
    "for i in range(y.shape[0]):\n",
    "        y_train_mapped[i] = dict_[y[i]]\n",
    "print(\"stop time\", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d39220f7-a692-4ff9-94a2-200bba8e9ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LTAE'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_model =['RF', 'LTAE']\n",
    "str_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b22e7e-87e6-4442-bb10-3dafaa4d621e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 12., 13., 14.,\n",
       "       15., 16., 17., 18., 19., 23.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee1dddbc-4ba3-41e6-9496-b341ec9376ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 10784283, Val 1606360, Test 1701000\n"
     ]
    }
   ],
   "source": [
    "for x, y, z in l_se:\n",
    "    print('Train {}, Val {}, Test {}'.format(len(x), len(y), len(z)))\n",
    "    # print('Starting Fold {}'.format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b331b92-15de-4d5e-9f73-34c56cbab848",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67c0868a-8005-4f15-ab40-47bde5d2a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_todevice(x, device):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.to(device)\n",
    "    else:\n",
    "        return [recursive_todevice(c, device) for c in x]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
