{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82866ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "# from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from utils import load_npz, read_ids\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be068f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a .npz file\n",
    "    \"\"\"\n",
    "    with np.load(file_path) as data:\n",
    "        X = data[\"X\"]\n",
    "        y = data[\"y\"]\n",
    "        block_ids = data[\"block_ids\"]\n",
    "    return X, y, block_ids#, polygon_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4bae7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 33\n",
    "n_channel = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aba8eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    \"\"\"\n",
    "    X: ()\n",
    "    \"\"\"\n",
    "    m = X.mean(axis=0)\n",
    "    s = X.std(axis=0)\n",
    "    X = (X - m) / s\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5802178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.99216985702515\n"
     ]
    }
   ],
   "source": [
    "source_sits = \"../../../data/theiaL2A_zip_img/output/2018/2018_SITS_data.npz\"\n",
    "train_val_eval = \"../RF_model/train_val_eval_rf.txt\"\n",
    "\n",
    "train_ids, test_ids = read_ids(train_val_eval)\n",
    "X_source, y_source, block_ids_source = load_npz(source_sits)\n",
    "_source = np.concatenate((X_source, y_source[:, None], block_ids_source[:, None]), axis=1)\n",
    "_source = _source[np.isin(_source[:, -1], train_ids)]\n",
    "Xtrain_source = _source[:, :-2]\n",
    "ytrain_source = _source[:, -2]\n",
    "# Xtrain = np.concatenate((Xtrain_source, Xtrain_target), axis=0)\n",
    "# ytrain = np.concatenate((ytrain_source, ytrain_target), axis=0)\n",
    "Xtrain = Xtrain_source\n",
    "ytrain = ytrain_source\n",
    "x, y = Xtrain, ytrain\n",
    "x = x.reshape(x.shape[0], L, n_channel)\n",
    "x = x.transpose(0,2,1)\n",
    "startime =time.time()\n",
    "x_ = (standardize(x)).astype('float16')\n",
    "print(time.time() - startime)\n",
    "# x_ = x[idx]\n",
    "# y = y.astype('int8')[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014e0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x.mean(axis=0)).shape\n",
    "# x.std(axis=0).astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c406364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c69cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_sits = \"../subset_data/2018_subset.npz\"\n",
    "# target_sits = \"../subset_data/2019_subset.npz\"\n",
    "# train_val_eval = \"train_val_eval_rf.txt\"\n",
    "# case = 1\n",
    "# set_ = \"trainval\"\n",
    "# # loader = data.DataLoader(dataset, batch_size = 10)\n",
    "# transform = None\n",
    "# import time\n",
    "# st = time.time()\n",
    "# dataset = SitsData(case, source_sits, target_sits, train_val_eval, set_, transform)\n",
    "# loader = data.DataLoader(dataset, batch_size = 10)\n",
    "# v, y = next(iter(loader))\n",
    "# print(\"run time: \", st -time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44083f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = data.DataLoader(dataset, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff158e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v, y = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c01bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf94786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SITSData(data.Dataset):\n",
    "    def __init__(self, case: int, source_sits, target_sits, train_val_eval, set_= 'trainval', transform=None):\n",
    "        ## OPTION 1 (good)\n",
    "        # sits\n",
    "        ## OPTION 2 (not good)\n",
    "        # [source_sits] case 2\n",
    "        # [source_list, target_list] case 1\n",
    "        self.source_sits = source_sits\n",
    "        self.target_sits = target_sits\n",
    "        self.train_val_eval = train_val_eval\n",
    "        self.transform = transform\n",
    "        self.case = case\n",
    "        self.set_ = set_\n",
    "\n",
    "        # read the set ids\n",
    "        start_time = time.time()\n",
    "        self.train_ids, self.test_ids = read_ids(self.train_val_eval)\n",
    "        print(\"read ids %s seconds ---\" % (time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "        # case selection\n",
    "        if self.set_ == 'trainval':\n",
    "            ids = self.train_ids\n",
    "        elif self.set_ == 'test':\n",
    "            ids = self.test_ids\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a set between trainval and test\")\n",
    "        print(\"case %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        # read the data \n",
    "        start_time = time.time()\n",
    "        X_source, y_source, block_ids_source = load_npz(self.source_sits)\n",
    "        X_target, y_target, block_ids_target = load_npz(self.target_sits)\n",
    "        print(\"load npz %s minutes ---\" % ((time.time() - start_time) / 60))\n",
    "\n",
    "        start_time = time.time()\n",
    "        _source = np.concatenate((X_source, y_source[:, None], block_ids_source[:, None]), axi =1)\n",
    "        _target = np.concatenate((X_target, y_target[:, None], block_ids_target[:, None]), axis=1)\n",
    "        print(\"concatenate %s minutes ---\" % ((time.time() - start_time) / 60))\n",
    "\n",
    "        start_time = time.time()\n",
    "        _source = _source[np.isin(_source[:, -1], ids)]\n",
    "        _target = _target[np.isin(_target[:, -1], ids)]\n",
    "        print(\"isin %s minutes ---\" % ((time.time() - start_time) / 60))\n",
    "\n",
    "        start_time = time.time()\n",
    "        self.Xtrain_source = _source[:, :-2]\n",
    "        self.ytrain_source = _source[:, -2]\n",
    "        print(\"remove ids source %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        start_time = time.time()\n",
    "        self.Xtrain_target = _target[:, :-2]\n",
    "        self.ytrain_target = _target[:, -2]\n",
    "        print(\"remove ids target %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        start_time = time.time()\n",
    "        if self.case == 1:\n",
    "            self.Xtrain = np.concatenate((self.Xtrain_source, self.Xtrain_target), axis=0)\n",
    "            self.ytrain = np.concatenate((self.ytrain_source, self.ytrain_target), axis=0)\n",
    "        elif self.case == 2:\n",
    "            self.Xtrain = self.Xtrain_source\n",
    "            self.ytrain = self.ytrain_source\n",
    "        elif self.case == 3:\n",
    "            self.Xtrain = self.Xtrain_target\n",
    "            self.ytrain = self.ytrain_target\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a case between 1 and 3\") \n",
    "        print(\"concatenate %s minutes ---\" % ((time.time() - start_time) / 60))\n",
    "        \n",
    "        # Reqd meqn qnd std\n",
    "        if year = \"2018\":\n",
    "            read(...)\n",
    "        else:\n",
    "            reas(...)\n",
    "        mean = np.mean(...)\n",
    "        std = np.mean(...)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ytrain)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_time = time.time()\n",
    "        x = self.Xtrain[idx]\n",
    "        x, y = self.Xtrain, self.ytrain\n",
    "        x = x.reshape(x.shape[0], L, n_channel)\n",
    "        x = x.transpose(0,2,1)\n",
    "        print(\"reshape and transpose %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        x = (standardize(x)).astype('float32')\n",
    "        x_ = x[idx]\n",
    "        y = y.astype('int8')[idx]\n",
    "        print(\"stardardization %s seconds ---\" % (time.time() - start_time))\n",
    "        # start_time = time.time()\n",
    "        # x_ = torch.from_numpy(np.array(x_))\n",
    "        # y = torch.from_numpy(np.array(y))\n",
    "        # print(\"to tenors %s seconds ---\" % (time.time() - start_time))\n",
    "        # return x, y\n",
    "        return torch.from_numpy(np.array(x_)), torch.from_numpy(np.array(y))\n",
    "\n",
    "def standardize(X, year=\"2018\"):\n",
    "    \"\"\"\n",
    "    X: (b,D,L)\n",
    "    \"\"\"\n",
    "    #print(X)\n",
    "    print(X.shape)\n",
    "    m = X.mean(axis=0) # axis=(0,2)\n",
    "    #print(\"mean: \", m)\n",
    "    s = X.std(axis=0)\n",
    "    X = (X - m) / s\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c5c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_sits = \"../../../data/theiaL2A_zip_img/output/2018/2018_SITS_data.npz\"\n",
    "# load_npz(source_sits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb980b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ids 0.0020072460174560547 seconds ---\n",
      "case 2.6226043701171875e-06 seconds ---\n",
      "load npz 2.311331498622894 minutes ---\n",
      "concatenate 0.12044020891189575 minutes ---\n",
      "isin 0.21219375928243 minutes ---\n",
      "remove ids source 3.457069396972656e-05 seconds ---\n",
      "remove ids target 2.0265579223632812e-05 seconds ---\n",
      "concatenate 0.06584848562876383 minutes ---\n",
      "run time:  2.7105690161387126\n"
     ]
    }
   ],
   "source": [
    "#source_sits = \"../subset_data/2018_subset.npz\"\n",
    "#target_sits = \"../subset_data/2019_subset.npz\"\n",
    "# train_val_eval = \"train_val_eval_rf.txt\"\n",
    "source_sits = \"../../../data/theiaL2A_zip_img/output/2018/2018_SITS_data.npz\"\n",
    "target_sits = \"../../../data/theiaL2A_zip_img/output/2019/2019_SITS_data.npz\"\n",
    "train_val_eval = \"../RF_model/train_val_eval_rf.txt\"\n",
    "case = 1\n",
    "set_ = \"trainval\"\n",
    "transform = None\n",
    "import time\n",
    "start_time = time.time()\n",
    "train_dataset = SITSData(case, source_sits, target_sits, train_val_eval, set_, transform)\n",
    "test_dataset = \n",
    "train_loader = data.DataLoader(train_dataset, batch_size = 1, pin_memory=True)\n",
    "\n",
    "print(\"run time: \", ((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e66e9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape and transpose 1.3828277587890625e-05 seconds ---\n",
      "(16415862, 10, 33)\n",
      "stardardization 82.17333197593689 seconds ---\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train= next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e66a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape and transpose 4.029273986816406e-05 seconds ---\n",
      "stardardization 82.94411087036133 seconds ---\n",
      "reshape and transpose 3.147125244140625e-05 seconds ---\n",
      "stardardization 82.9876160621643 seconds ---\n",
      "reshape and transpose 4.673004150390625e-05 seconds ---\n"
     ]
    }
   ],
   "source": [
    "for (x,y) in enumerate(train_loader):\n",
    "    y_ry = y\n",
    "    x_hr = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a532f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ids 0.002400636672973633 seconds ---\n",
      "case 1.9073486328125e-06 seconds ---\n",
      "load npz 1.9369140625 minutes ---\n",
      "concatenate 0.12013090848922729 minutes ---\n",
      "isin 0.14379287560780843 minutes ---\n",
      "remove ids source 4.100799560546875e-05 seconds ---\n",
      "remove ids target 5.245208740234375e-06 seconds ---\n",
      "concatenate 0.0441957155863444 minutes ---\n",
      "run time:  134.75104451179504\n"
     ]
    }
   ],
   "source": [
    "source_sits = \"../../../data/theiaL2A_zip_img/output/2018/2018_SITS_data.npz\"\n",
    "target_sits = \"../../../data/theiaL2A_zip_img/output/2019/2019_SITS_data.npz\"\n",
    "train_val_eval = \"../RF_model/train_val_eval_rf.txt\"\n",
    "case = 1\n",
    "set_ = \"test\"\n",
    "transform = None\n",
    "import time\n",
    "st = time.time()\n",
    "dataset_test = SITSData(case, source_sits, target_sits, train_val_eval, set_, transform)\n",
    "test_loader = data.DataLoader(dataset_test, batch_size = 1, pin_memory=True)\n",
    "# x_test,y_test= next(iter(loader))\n",
    "print(\"run time: \", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a7229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape and transpose 2.7179718017578125e-05 seconds ---\n",
      "stardardization 54.03708863258362 seconds ---\n",
      "to tenors 0.030365467071533203 seconds ---\n",
      "run time:  0.9012147784233093\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "x_test,y_test= next(iter(test_loader))\n",
    "print(\"run time: \", ((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a341fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495f8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # useful functions that are needed in the dataset class\n",
    "# class SitsData(data.Dataset):\n",
    "#     def __init__(self, case: int, source_sits, target_sits, train_val_eval, set_= 'trainval', transform=None):\n",
    "#         super(SitsData, self).__init__()\n",
    "#         self.source_sits = source_sits\n",
    "#         self.target_sits = target_sits\n",
    "#         self.train_val_eval = train_val_eval\n",
    "#         self.transform = transform\n",
    "#         self.case = case\n",
    "#         self.set_ = set_\n",
    "        \n",
    "#         self.x, self.y = self._init_dataset()\n",
    "        \n",
    "#     def load_set(self, total_set):\n",
    "#         \"\"\"\n",
    "#             Load a set of data:\n",
    "#             to be used in prepare_data(), it organise dataset according to the set_name based block_ids\n",
    "#             - set_name: train or test (reads from the block_ids using read_ids() utils) \n",
    "#             - total_set: the concatenated set of data for source or target\n",
    "#             - returns X and Y:\n",
    "#                 X is the data, Y is the label\n",
    "#         \"\"\"\n",
    "#         self.train_ids, self.test_ids = read_ids(self.train_val_eval)\n",
    "\n",
    "#         if self.set_ == \"trainval\":\n",
    "#             ids = self.train_ids\n",
    "#         elif self.set_ == \"test\":\n",
    "#             ids = self.test_ids\n",
    "#         else:\n",
    "#             raise ValueError(\"Please choose a set between trainval and test\")\n",
    "\n",
    "#         set = total_set[np.isin(total_set[:, -1], ids)]\n",
    "#         X = set[:, :-2]\n",
    "#         Y = set[:, -2]\n",
    "            \n",
    "#         return X, Y\n",
    "        \n",
    "#     def _init_dataset(self):\n",
    "#         \"\"\"\n",
    "#             Prepare data:\n",
    "#             - load data from npz files(load_npz() in utils): returns X, Y and block_ids\n",
    "#             - concatenate the data from source and target [X, Y, block_ids] == total_set\n",
    "#             - split the data into train and test sets for source and target\n",
    "#             - returns Xtrain and Ytrain base on CASE value\n",
    "#             CASE: \n",
    "#             - 1: Train on Soucre and target, test on source and target\n",
    "#             - 2: Train on Source only, test on Source and target\n",
    "#             - 3: Train on Target only, test on Source and target\n",
    "#         \"\"\"\n",
    "#             # print(\"Preparing data.........\")\n",
    "\n",
    "#         X_s, Y_s, block_ids_s = load_npz(self.source_sits)\n",
    "#         X_t, Y_t, block_ids_t = load_npz(self.target_sits)\n",
    "#         # print(\"Loading npz files done.........\")\n",
    "            \n",
    "\n",
    "#         self.total_set_s = np.concatenate((X_s, Y_s[:, None], block_ids_s[:, None]), axis=1)\n",
    "#         self.total_set_t = np.concatenate((X_t, Y_t[:, None], block_ids_t[:, None]), axis=1)\n",
    "#             # print(\"Concatenating data done.........\")\n",
    "\n",
    "#             # Training set for target and source\n",
    "#         self.Xtrain_s, self.Ytrain_s = self.load_set(self.total_set_s)\n",
    "#         self.Xtrain_t, self.Ytrain_t = self.load_set(self.total_set_t)\n",
    "#             # print(\"Loading train set done.........\")\n",
    "\n",
    "#             # Test set for target and source\n",
    "#         self.Xtest_s, self.Ytest_s = self.load_set(self.total_set_s)\n",
    "#         self.Xtest_t, self.Ytest_t = self.load_set(self.total_set_t)\n",
    "#             # print(\"Loading test set done.........\")\n",
    "\n",
    "#         if self.case == 1:\n",
    "#                 # concatenate training set for target and source\n",
    "#             self.Xtrain = np.concatenate((self.Xtrain_s, self.Xtrain_t), axis=0)\n",
    "#             self.Ytrain = np.concatenate((self.Ytrain_s, self.Ytrain_t), axis=0)\n",
    "\n",
    "#         elif self.case == 2:\n",
    "#                 # Xtrain is the training set for source only\n",
    "#             self.Xtrain = self.Xtrain_s\n",
    "#             self.Ytrain = self.Ytrain_s\n",
    "\n",
    "#         elif self.case == 3:\n",
    "#                 # Xtrain is the training set for target only\n",
    "#             self.Xtrain = self.Xtrain_t\n",
    "#             self.Ytrain = self.Ytrain_t\n",
    "\n",
    "#         else:\n",
    "#             raise ValueError(\"Please choose a case between 1 and 3\")\n",
    "            \n",
    "#         return self.Xtrain, self.Ytrain\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.y)\n",
    "        \n",
    "#     def __getitem__(self, idx):\n",
    "#         x_, y_ = self.x[idx], self.y[idx]\n",
    "            \n",
    "#         x = torch.from_numpy(np.array(x_, dtype=int))\n",
    "#         y = torch.from_numpy(np.array(y_, dtype=int))\n",
    "#         return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8225c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file= '../RF_model/models/rf_model_2.pkl'\n",
    "ref_file = '../../../data/theiaL2A_zip_img/output/2018/2018_SITS_data.npz'\n",
    "in_img = '../../../data/theiaL2A_zip_img/output/2018/2018_GapFilled_Image.tif'\n",
    "out_path = '../../../results/RF'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
