{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e40c887-a0e1-425e-9a17-5ddaf831bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "# from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from utils import load_npz, read_ids\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508ec429-bfa4-486e-918d-e376bba22a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 33\n",
    "n_channel = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dcb2390-5c04-426a-87c5-36613d147041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SITSData(data.Dataset):\n",
    "    \n",
    "#     def __init__(self, case: int, source_sits, target_sits, train_val_eval, set= 'trainval', transform=None):\n",
    "        \n",
    "#         \"\"\"\n",
    "#         Dataset for SITS data.\n",
    "#         \"\"\"\n",
    "#         # super(SITSData, self).__init__()\n",
    "        \n",
    "#         self.source_sits = source_sits\n",
    "#         self.target_sits = target_sits\n",
    "#         self.train_val_eval = train_val_eval\n",
    "#         self.transform = transform\n",
    "#         self.case = case\n",
    "#         self.set_ = set\n",
    "#         # self.prepare_data()\n",
    "\n",
    "\n",
    "#         def __len__(self):\n",
    "#             return len(self.prepare_data()[1])\n",
    "\n",
    "#         def __getitem__(self, idx):\n",
    "#             self.data = self.prepare_data()\n",
    "#             X = self.data[0][idx]\n",
    "#             y = self.data[1][idx]\n",
    "#             # reshape X to (n, T, d)\n",
    "#             X = X.reshape(X.shape[0], L, n_channel)\n",
    "#             # transpose X to (n, d, T)\n",
    "#             X = X.transpose(0, 2, 1)\n",
    "#             # standardize X\n",
    "#             X = standardize(X)\n",
    "#             # convert X and y to torch tensor\n",
    "#             X = torch.from_numpy(X)\n",
    "#             y = torch.from_numpy(y)\n",
    "#             return X, y\n",
    "\n",
    "#         def load_set(self, total_set):\n",
    "#             \"\"\"\n",
    "#             Load a set of data:\n",
    "#             to be used in prepare_data(), it organise dataset according to the set_name based block_ids\n",
    "#             - set_name: train or test (reads from the block_ids using read_ids() utils) \n",
    "#             - total_set: the concatenated set of data for source or target\n",
    "#             - returns X and Y:\n",
    "#                 X is the data, Y is the label\n",
    "#             \"\"\"\n",
    "#             self.train_ids, self.test_ids = read_ids(self.train_val_eval)\n",
    "\n",
    "#             if self.set_ == \"trainval\":\n",
    "#                 ids = self.train_ids\n",
    "#             elif self.set_ == \"test\":\n",
    "#                 ids = self.test_ids\n",
    "#             else:\n",
    "#                 raise ValueError(\"Please choose a set between train and test\")\n",
    "\n",
    "#             set = total_set[np.isin(total_set[:, -1], ids)]\n",
    "#             X = set[:, :-2]\n",
    "#             Y = set[:, -2]\n",
    "            \n",
    "#             return X, Y\n",
    "\n",
    "#         def prepare_data(self):\n",
    "#             \"\"\"\n",
    "#             Prepare data:\n",
    "#             - load data from npz files(load_npz() in utils): returns X, Y and block_ids\n",
    "#             - concatenate the data from source and target [X, Y, block_ids] == total_set\n",
    "#             - split the data into train and test sets for source and target\n",
    "#             - returns Xtrain and Ytrain base on CASE value\n",
    "#             CASE: \n",
    "#             - 1: Train on Soucre and target, test on source and target\n",
    "#             - 2: Train on Source only, test on Source and target\n",
    "#             - 3: Train on Target only, test on Source and target\n",
    "#             \"\"\"\n",
    "#             # print(\"Preparing data.........\")\n",
    "\n",
    "#             X_s, Y_s, block_ids_s = load_npz(self.source_sits)\n",
    "#             X_t, Y_t, block_ids_t = load_npz(self.target_sits)\n",
    "#             # print(\"Loading npz files done.........\")\n",
    "            \n",
    "\n",
    "#             self.total_set_s = np.concatenate(\n",
    "#                 (X_s, Y_s[:, None], block_ids_s[:, None]), axis=1)\n",
    "#             self.total_set_t = np.concatenate((X_t, Y_t[:, None], block_ids_t[:, None]), axis=1)\n",
    "#             # print(\"Concatenating data done.........\")\n",
    "\n",
    "#             # Training set for target and source\n",
    "#             self.Xtrain_s, self.Ytrain_s = self.load_set(self.total_set_s)\n",
    "#             self.Xtrain_t, self.Ytrain_t = self.load_set(self.total_set_t)\n",
    "#             # print(\"Loading train set done.........\")\n",
    "\n",
    "#             # Test set for target and source\n",
    "#             self.Xtest_s, self.Ytest_s = self.load_set(self.total_set_s)\n",
    "#             self.Xtest_t, self.Ytest_t = self.load_set(self.total_set_t)\n",
    "#             # print(\"Loading test set done.........\")\n",
    "\n",
    "#             if self.case == 1:\n",
    "#                 # concatenate training set for target and source\n",
    "#                 self.Xtrain = np.concatenate((self.Xtrain_s, self.Xtrain_t), axis=0)\n",
    "#                 self.Ytrain = np.concatenate((self.Ytrain_s, self.Ytrain_t), axis=0)\n",
    "\n",
    "#             elif self.case == 2:\n",
    "#                 # Xtrain is the training set for source only\n",
    "#                 self.Xtrain = self.Xtrain_s\n",
    "#                 self.Ytrain = self.Ytrain_s\n",
    "\n",
    "#             elif self.case == 3:\n",
    "#                 # Xtrain is the training set for target only\n",
    "#                 self.Xtrain = self.Xtrain_t\n",
    "#                 self.Ytrain = self.Ytrain_t\n",
    "\n",
    "#             else:\n",
    "#                 raise ValueError(\"Please choose a case between 1 and 3\")\n",
    "            \n",
    "#             # self.Xtrain, self.Ytrain = shuffle(self.Xtrain, self.Ytrain)\n",
    "#             # print(\"Preparing data completed.........\")\n",
    "#             # return Xtrain and Ytrain together in an array\n",
    "#             return self.Xtrain, self.Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c41127a-3c97-4783-9698-fff87d77cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_sits = \"../subset_data/2018_subset.npz\"\n",
    "# target_sits = \"../subset_data/2019_subset.npz\"\n",
    "# train_val_eval = \"train_val_eval_rf.txt\"\n",
    "# case = 2\n",
    "# set = \"trainval\"\n",
    "# transform = None\n",
    "# dataset = SITSData(case, source_sits, target_sits, train_val_eval, set, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f19f92b7-0327-4e98-a006-6084b01a03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cdataset(data.Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        \n",
    "        super(cdataset, self).__init__()\n",
    "        self.file_ = file_path\n",
    "        \n",
    "        self.X_s, self.Y_s, self.block_ids_s = load_npz(self.file_)\n",
    "        # print('X_s shape:', self.X_s.shape)\n",
    "        # print('Y_s shape:', self.Y_s.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.Y_s)\n",
    "    def __getitem__(self, idx):\n",
    "        xtrain, ytrain = (self.X_s[idx]).astype(np.int16), (self.Y_s[idx]).astype(np.int16)\n",
    "        \n",
    "        print('x shape:',xtrain.shape)\n",
    "        print('y shape:', ytrain.shape)\n",
    "        # print('xtrain')\n",
    "        # print(xtrain)\n",
    "        # print('ytrain')\n",
    "        # print(ytrain)\n",
    "        x = torch.from_numpy(xtrain)\n",
    "        y = torch.from_numpy(np.array(ytrain))\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c8021954-517d-4adf-adc2-fc7be07d5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sits = \"../subset_data/2018_subset.npz\"\n",
    "dt = cdataset(source_sits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074be3a9-6b12-44bd-a4fb-f865c0a117c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ad187107-70c7-44b2-aaee-c05fb6c822ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = data.DataLoader(dt, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1f03f01a-7103-4059-8bdf-c47b5ed608a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ebe55daa-958b-4759-90ea-9f6da00c81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful functions that are needed in the dataset class\n",
    "# def load_set(total_set, ids_text):\n",
    "#     \"\"\"\n",
    "#             Load a set of data:\n",
    "#             to be used in prepare_data(), it organise dataset according to the set_name based block_ids\n",
    "#             - set_name: train or test (reads from the block_ids using read_ids() utils) \n",
    "#             - total_set: the concatenated set of data for source or target\n",
    "#             - ids_text: varaible repin path to id text\n",
    "#             - returns X and Y:\n",
    "#                 X is the data, Y is the label\n",
    "#     \"\"\"\n",
    "#     train_ids, test_ids = read_ids(ids_text)\n",
    "\n",
    "#     if selfset == \"trainval\":\n",
    "#         ids = train_ids\n",
    "#     elif self.set_ == \"test\":\n",
    "#         ids = self.test_ids\n",
    "#     else:\n",
    "#         raise ValueError(\"Please choose a set between train and test\")\n",
    "\n",
    "#     set = total_set[np.isin(total_set[:, -1], ids)]\n",
    "#     X = set[:, :-2]\n",
    "#     Y = set[:, -2]\n",
    "            \n",
    "#     return X, Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b40035ce-2ad3-4cdf-8c7f-ab0f124a7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # useful functions that are needed in the dataset class\n",
    "# class SitsData(data.Dataset):\n",
    "#     def __init__(self, case: int, source_sits, target_sits, train_val_eval, set= 'trainval', transform=None):\n",
    "#         # super(SitsData, self).__init__()\n",
    "#         self.source_sits = source_sits\n",
    "#         self.target_sits = target_sits\n",
    "#         self.train_val_eval = train_val_eval\n",
    "#         self.transform = transform\n",
    "#         self.case = case\n",
    "#         self.set_ = set\n",
    "        \n",
    "#         # self._init_dataset()\n",
    "        \n",
    "#         def load_set(self, total_set):\n",
    "#             \"\"\"\n",
    "#             Load a set of data:\n",
    "#             to be used in prepare_data(), it organise dataset according to the set_name based block_ids\n",
    "#             - set_name: train or test (reads from the block_ids using read_ids() utils) \n",
    "#             - total_set: the concatenated set of data for source or target\n",
    "#             - returns X and Y:\n",
    "#                 X is the data, Y is the label\n",
    "#             \"\"\"\n",
    "#             self.train_ids, self.test_ids = read_ids(self.train_val_eval)\n",
    "\n",
    "#             if self.set_ == \"trainval\":\n",
    "#                 ids = self.train_ids\n",
    "#             elif self.set_ == \"test\":\n",
    "#                 ids = self.test_ids\n",
    "#             else:\n",
    "#                 raise ValueError(\"Please choose a set between trainval and test\")\n",
    "\n",
    "#             set = total_set[np.isin(total_set[:, -1], ids)]\n",
    "#             X = set[:, :-2]\n",
    "#             Y = set[:, -2]\n",
    "            \n",
    "#             return X, Y\n",
    "        \n",
    "#         def _init_dataset(self):\n",
    "#             \"\"\"\n",
    "#             Prepare data:\n",
    "#             - load data from npz files(load_npz() in utils): returns X, Y and block_ids\n",
    "#             - concatenate the data from source and target [X, Y, block_ids] == total_set\n",
    "#             - split the data into train and test sets for source and target\n",
    "#             - returns Xtrain and Ytrain base on CASE value\n",
    "#             CASE: \n",
    "#             - 1: Train on Soucre and target, test on source and target\n",
    "#             - 2: Train on Source only, test on Source and target\n",
    "#             - 3: Train on Target only, test on Source and target\n",
    "#             \"\"\"\n",
    "#             # print(\"Preparing data.........\")\n",
    "\n",
    "#             X_s, Y_s, block_ids_s = load_npz(self.source_sits)\n",
    "#             X_t, Y_t, block_ids_t = load_npz(self.target_sits)\n",
    "#             print(\"Loading npz files done.........\")\n",
    "            \n",
    "\n",
    "#             self.total_set_s = np.concatenate((X_s, Y_s[:, None], block_ids_s[:, None]), axis=1)\n",
    "#             self.total_set_t = np.concatenate((X_t, Y_t[:, None], block_ids_t[:, None]), axis=1)\n",
    "#             # print(\"Concatenating data done.........\")\n",
    "\n",
    "#             # Training set for target and source\n",
    "#             self.Xtrain_s, self.Ytrain_s = self.load_set(self.total_set_s)\n",
    "#             self.Xtrain_t, self.Ytrain_t = self.load_set(self.total_set_t)\n",
    "#             # print(\"Loading train set done.........\")\n",
    "\n",
    "#             # Test set for target and source\n",
    "#             self.Xtest_s, self.Ytest_s = self.load_set(self.total_set_s)\n",
    "#             self.Xtest_t, self.Ytest_t = self.load_set(self.total_set_t)\n",
    "#             # print(\"Loading test set done.........\")\n",
    "\n",
    "#             if self.case == 1:\n",
    "#                 # concatenate training set for target and source\n",
    "#                 self.Xtrain = np.concatenate((self.Xtrain_s, self.Xtrain_t), axis=0)\n",
    "#                 self.Ytrain = np.concatenate((self.Ytrain_s, self.Ytrain_t), axis=0)\n",
    "\n",
    "#             elif self.case == 2:\n",
    "#                 # Xtrain is the training set for source only\n",
    "#                 self.Xtrain = self.Xtrain_s\n",
    "#                 self.Ytrain = self.Ytrain_s\n",
    "\n",
    "#             elif self.case == 3:\n",
    "#                 # Xtrain is the training set for target only\n",
    "#                 self.Xtrain = self.Xtrain_t\n",
    "#                 self.Ytrain = self.Ytrain_t\n",
    "\n",
    "#             else:\n",
    "#                 raise ValueError(\"Please choose a case between 1 and 3\")\n",
    "            \n",
    "#             return self.Xtrain, self.Ytrain\n",
    "        \n",
    "#         def __len__(self):\n",
    "#             return len(self.y)\n",
    "        \n",
    "#         def __getitem__(self, idx):\n",
    "#             x_, y_ = self.x[idx], self.y[idx]\n",
    "            \n",
    "#             x = torch.from_numpy(x_)\n",
    "#             y = torch.from_numpy(np.array(y_))\n",
    "#             return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "15abcb2a-934e-4f66-a1f4-9da76894afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_sits = \"../subset_data/2018_subset.npz\"\n",
    "# target_sits = \"../subset_data/2019_subset.npz\"\n",
    "# train_val_eval = \"train_val_eval_rf.txt\"\n",
    "# case = 2\n",
    "# set = \"trainval\"\n",
    "# transform = None\n",
    "# dataset = SitsData(case, source_sits, target_sits, train_val_eval, set, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ed07ee55-9a88-4f0b-bcfe-f3f51359f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SitsData._init_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c980a301-d9bc-42a8-8207-8bfc5598a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SITSData(data.Dataset):\n",
    "    def __init__(self, case: int, source_sits, target_sits, train_val_eval, set_= 'trainval', transform=None):\n",
    "        self.source_sits = source_sits\n",
    "        self.target_sits = target_sits\n",
    "        self.train_val_eval = train_val_eval\n",
    "        self.transform = transform\n",
    "        self.case = case\n",
    "        self.set_ = set_\n",
    "\n",
    "        # read the set ids\n",
    "        self.train_ids, self.test_ids = read_ids(self.train_val_eval)\n",
    "\n",
    "        # case selection\n",
    "        if self.set_ == 'trainval':\n",
    "            ids = self.train_ids\n",
    "        elif self.set_ == 'test':\n",
    "            ids = self.test_ids\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a set between trainval and test\")\n",
    "\n",
    "        # read the data \n",
    "\n",
    "        X_source, y_source, block_ids_source = load_npz(self.source_sits)\n",
    "        X_target, y_target, block_ids_target = load_npz(self.target_sits)\n",
    "\n",
    "        _source = np.concatenate((X_source, y_source[:, None], block_ids_source[:, None]), axis=1)\n",
    "        _target = np.concatenate((X_target, y_target[:, None], block_ids_target[:, None]), axis=1)\n",
    "\n",
    "        _source = _source[np.isin(_source[:, -1], ids)]\n",
    "        _target = _target[np.isin(_target[:, -1], ids)]\n",
    "\n",
    "        self.Xtrain_source = _source[:, :-2]\n",
    "        self.ytrain_source = _source[:, -2]\n",
    "\n",
    "        self.Xtrain_target = _target[:, :-2]\n",
    "        self.ytrain_target = _target[:, -2]\n",
    "\n",
    "        if self.case == 1:\n",
    "            self.Xtrain = np.concatenate((self.Xtrain_source, self.Xtrain_target), axis=0)\n",
    "            self.ytrain = np.concatenate((self.ytrain_source, self.ytrain_target), axis=0)\n",
    "        elif self.case == 2:\n",
    "            self.Xtrain = self.Xtrain_source\n",
    "            self.ytrain = self.ytrain_source\n",
    "        elif self.case == 3:\n",
    "            self.Xtrain = self.Xtrain_target\n",
    "            self.ytrain = self.ytrain_target\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a case between 1 and 3\")      \n",
    "\n",
    "        print(\"The number of training samples is: \", self.Xtrain.shape[0])\n",
    "        print(\"The number of training samples is: \", len(self.ytrain))  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ytrain)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.Xtrain[idx]\n",
    "        y = self.ytrain[idx]\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0989d84e-934d-4d12-8f2e-2ab369d62214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples is:  194\n",
      "The number of training samples is:  194\n"
     ]
    }
   ],
   "source": [
    "source_sits = \"../subset_data/2018_subset.npz\"\n",
    "target_sits = \"../subset_data/2019_subset.npz\"\n",
    "train_val_eval = \"train_val_eval_rf.txt\"\n",
    "case = 2\n",
    "set_ = \"trainval\"\n",
    "transform = None\n",
    "dataset = SITSData(case, source_sits, target_sits, train_val_eval, set_, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a712d569-7223-4f90-8a20-75bfef11cff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9a54688b-cbdf-4b7d-beb7-bdffcd037e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = data.DataLoader(dataset, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "239ec5e1-816a-44ae-922b-d69a9ffdd8f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.uint16. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-a4387374ec55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/python_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_env/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/python_env/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_env/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_env/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/python_env/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.uint16. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c13fac-5a3a-4fda-877c-4fc9dc9852a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
