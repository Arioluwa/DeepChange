{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# import os\n",
    "from utils.utils import load_npz, read_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 33\n",
    "n_channel = 10\n",
    "\n",
    "def standardize(X):\n",
    "    m = X.mean(axis=1)\n",
    "    s = X.std(axis=1)\n",
    "    X = (X - m) / s\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a .npz file\n",
    "    \"\"\"\n",
    "    with np.load(file_path) as data:\n",
    "        X = data[\"X\"]\n",
    "        y = data[\"y\"]\n",
    "        # polygon_ids = data[\"polygon_ids\"]\n",
    "        block_ids = data[\"block_id\"]\n",
    "    return X, y, block_ids#, polygon_ids\n",
    "\n",
    "######### Read Train, Validation, and Test ids #########\n",
    "\n",
    "def read_ids(file_path):\n",
    "    \"\"\"\n",
    "    Read ids from file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        Train_ids = eval(lines[0].split(\":\")[1])\n",
    "        test_ids = eval(lines[1].split(\":\")[1])\n",
    "        # Eval_ids = eval(lines[2].split(\":\")[1])\n",
    "    return Train_ids, test_ids#, Eval_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SITSData(Dataset):\n",
    "    def __init__(self, case: int, source_sits, target_sits, train_val_eval, set= 'trainval', transform=None):\n",
    "        self.source_sits = source_sits\n",
    "        self.target_sits = target_sits\n",
    "        self.train_val_eval = train_val_eval\n",
    "        self.transform = transform\n",
    "        self.case = case\n",
    "        self.set = set\n",
    "        \n",
    "        # read the set ids\n",
    "        self.train_ids, self.test_ids = read_ids(self.train_val_eval)\n",
    "        \n",
    "        # case selection\n",
    "        if self.set == 'trainval':\n",
    "            ids = self.train_ids\n",
    "        elif self.set == 'test':\n",
    "            ids = self.test_ids\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a set between trainval and test\")\n",
    "\n",
    "        # read the data \n",
    "\n",
    "        X_source, y_source, block_ids_source = load_npz(self.source_sits)\n",
    "        X_target, y_target, block_ids_target = load_npz(self.target_sits)\n",
    "\n",
    "        _source = np.concatenate((X_source, y_source[:, None], block_ids_source[:, None]), axis=1)\n",
    "        _target = np.concatenate((X_target, y_target[:, None], block_ids_target[:, None]), axis=1)\n",
    "\n",
    "        _source = _source[np.isin(_source[:, -1], ids)]\n",
    "        _target = _target[np.isin(_target[:, -1], ids)]\n",
    "\n",
    "        self.Xtrain_source = _source[:, :-2]\n",
    "        self.ytrain_source = _source[:, -2]\n",
    "\n",
    "        self.Xtrain_target = _target[:, :-2]\n",
    "        self.ytrain_target = _target[:, -2]\n",
    "\n",
    "        if self.case == 1:\n",
    "            self.Xtrain = np.concatenate((self.Xtrain_source, self.Xtrain_target), axis=0)\n",
    "            self.ytrain = np.concatenate((self.ytrain_source, self.ytrain_target), axis=0)\n",
    "        elif self.case == 2:\n",
    "            self.Xtrain = self.Xtrain_source\n",
    "            self.ytrain = self.ytrain_source\n",
    "        elif self.case == 3:\n",
    "            self.Xtrain = self.Xtrain_target\n",
    "            self.ytrain = self.ytrain_target\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a case between 1 and 3\")      \n",
    "\n",
    "        print(\"The number of training samples is: \", self.Xtrain.shape[0])\n",
    "        print(\"The number of training samples is: \", self.ytrain.shape[0])  \n",
    "\n",
    "        def __len__(self):\n",
    "            return self.ytrain.shape[0]\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            X = self.Xtrain[idx]\n",
    "            y = self.ytrain[idx]\n",
    "            if self.transform:\n",
    "                X = self.transform(X)\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SITSData(Dataset):\n",
    "    def __init__(self, case: int, source_sits, target_sits, train_val_eval, set= 'trainval', transform=None):\n",
    "        self.source_sits = source_sits\n",
    "        self.target_sits = target_sits\n",
    "        self.train_val_eval = train_val_eval\n",
    "        self.transform = transform\n",
    "        self.case = case\n",
    "        self.set = set\n",
    "        \n",
    "        # read the set ids\n",
    "        self.train_ids, self.test_ids = read_ids(self.train_val_eval)\n",
    "        \n",
    "        # case selection\n",
    "        if self.set == 'trainval':\n",
    "            ids = self.train_ids\n",
    "        elif self.set == 'test':\n",
    "            ids = self.test_ids\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a set between trainval and test\")\n",
    "\n",
    "        # read the data \n",
    "\n",
    "        X_source, y_source, block_ids_source = load_npz(self.source_sits)\n",
    "        X_target, y_target, block_ids_target = load_npz(self.target_sits)\n",
    "\n",
    "        _source = np.concatenate((X_source, y_source[:, None], block_ids_source[:, None]), axis=1)\n",
    "        _target = np.concatenate((X_target, y_target[:, None], block_ids_target[:, None]), axis=1)\n",
    "\n",
    "        _source = _source[np.isin(_source[:, -1], ids)]\n",
    "        _target = _target[np.isin(_target[:, -1], ids)]\n",
    "\n",
    "        self.Xtrain_source = _source[:, :-2]\n",
    "        self.ytrain_source = _source[:, -2]\n",
    "\n",
    "        self.Xtrain_target = _target[:, :-2]\n",
    "        self.ytrain_target = _target[:, -2]\n",
    "\n",
    "        if self.case == 1:\n",
    "            self.Xtrain = np.concatenate((self.Xtrain_source, self.Xtrain_target), axis=0)\n",
    "            self.ytrain = np.concatenate((self.ytrain_source, self.ytrain_target), axis=0)\n",
    "        elif self.case == 2:\n",
    "            self.Xtrain = self.Xtrain_source\n",
    "            self.ytrain = self.ytrain_source\n",
    "        elif self.case == 3:\n",
    "            self.Xtrain = self.Xtrain_target\n",
    "            self.ytrain = self.ytrain_target\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a case between 1 and 3\")      \n",
    "\n",
    "        print(\"The number of training samples is: \", self.Xtrain.shape[0])\n",
    "        print(\"The number of training samples is: \", self.ytrain.shape[0])  \n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.ytrain)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            X = self.Xtrain[idx]\n",
    "            y = self.ytrain[idx]\n",
    "            if self.transform:\n",
    "                X = self.transform(X)\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples is:  5658378\n",
      "The number of training samples is:  5658378\n"
     ]
    }
   ],
   "source": [
    "source_sits = \"../../../data/theiaL2A_zip_img/output/2018/2018_SITS_data.npz\"\n",
    "target_sits = \"../../../data/theiaL2A_zip_img/output/2019/2019_SITS_data.npz\"\n",
    "train_val_eval = \"train_val_eval.txt\"\n",
    "case = 2\n",
    "set = \"trainval\"\n",
    "transform = None\n",
    "dataset = SITSData(case, source_sits, target_sits, train_val_eval, set, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SITSData' object has no attribute '__len__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9577e75d4bf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SITSData' object has no attribute '__len__'"
     ]
    }
   ],
   "source": [
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.ones((100, 10), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../2018_SITS_data.npz\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# load npz file\n",
    "npz_2018 = np.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errorcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "def changeErrorCheck(\n",
    "    change_map,\n",
    "    gt_source,\n",
    "    gt_target,\n",
    "    pred_source,\n",
    "    pred_target):\n",
    "\n",
    "    \"\"\"\n",
    "    Base on the error in the change map and confusion matrix, the No Change to Change category is inspected to know the source of error.\n",
    "\n",
    "    Output: Table \n",
    "        gt_source | gt_target | predicted_ source | predicted_target\n",
    "    Note: Source and Target in the case are 2018 and 2019 respectively\n",
    "    \"\"\"\n",
    "\n",
    "    # read change map\n",
    "    mask = None\n",
    "    with rasterio.open(change_map) as src:\n",
    "        crs_ = src.crs\n",
    "        img = src.read(1)\n",
    "        geom_atrri = ({'properties' : {'change_val': v}, 'geometry': s} for i, (s, v) in enumerate(shapes(img, mask=mask, transform=src.transform)))\n",
    "    ncc_gdf = gp.GeoDataFrame.from_features(geom_atrri, crs=crs_)\n",
    "    # select the No change to Change category\n",
    "    ncc_gdf = ncc_gdf[ncc_gdf['change_val'] == 2]\n",
    "    ncc_gdf['row_ix'] = ncc_gdf.index\n",
    "    # ncc_gdf = ncc_gdf.head(2000)\n",
    "    # print('nncc',ncc_gdf.head(2))\n",
    "\n",
    "    #free img \n",
    "    img = None\n",
    "    geom_atrri = None\n",
    "\n",
    "    # read gt_source and gt_target\n",
    "    gt_source = (gp.read_file(gt_source).to_crs(crs_))\n",
    "    # gt_source = gt_source.head(2000)\n",
    "    # print('gt_source..\\n',gt_source.head(2))\n",
    "    gt_target = (gp.read_file(gt_target)).to_crs(crs_)\n",
    "    # gt_target = gt_target.head(2000)\n",
    "    # print('gt_target... \\n',gt_target.head(2))\n",
    "    \n",
    "    # read pred_source and pred_target\n",
    "    def polygonize(raster_path, attribute_name):\n",
    "        \"\"\" returns polygon of the input raster\"\"\"\n",
    "        mask = None\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            img = src.read(1)\n",
    "            geom_atrri = ({'properties' : {'%s' % attribute_name: v}, 'geometry': s} for i, (s, v) in enumerate(shapes(img, mask=mask, transform=src.transform)))\n",
    "        gdf = gp.GeoDataFrame.from_features(geom_atrri, crs=crs_)\n",
    "        # gdf = gdf.head(2000)\n",
    "        img = None\n",
    "        return gdf\n",
    "    \n",
    "    pred_source = polygonize(pred_source, 'pred_18')\n",
    "    pred_target = polygonize(pred_target, 'pred_19')\n",
    "\n",
    "    # spatial join \n",
    "    # gt\n",
    "    gt_source_df = gp.sjoin(ncc_gdf, gt_source, how='inner', predicate='intersects')\n",
    "    gt_source_df = gt_source_df.rename(columns={'code': 'gt_source'})\n",
    "    # print('gt_source_df.. \\n',gt_source_df.head(2))\n",
    "    gt_target_df = gp.sjoin(ncc_gdf, gt_target, how='inner', predicate='intersects')\n",
    "    gt_target_df = gt_target_df.rename(columns={'code': 'gt_target'})\n",
    "    # print('gt_target_df.. \\n',gt_target_df.head(2))\n",
    "\n",
    "    # pred\n",
    "    pred_source_df = gp.sjoin(ncc_gdf, pred_source, how='inner', predicate='intersects')\n",
    "    # print('pred_source.. \\n', pred_source_df.head(2))\n",
    "    pred_target_df = gp.sjoin(ncc_gdf, pred_target, how='inner', predicate='intersects')\n",
    "    # print(pred_target_df.head(2))\n",
    "\n",
    "    # join ncc_gdf with gt_source_df['code'], gt_target_df['code'], pred_source_df['pred18'], pred_target_df['pred_19']\n",
    "    ncc_gdf = ncc_gdf.merge(gt_source_df[['row_ix', 'gt_source']], on='row_ix', how='left')\n",
    "    ncc_gdf = ncc_gdf.merge(gt_target_df[['row_ix', 'gt_target']], on='row_ix', how='left')\n",
    "    ncc_gdf = ncc_gdf.merge(pred_source_df[['row_ix', 'pred_18']], on='row_ix', how='left')\n",
    "    ncc_gdf = ncc_gdf.merge(pred_target_df[['row_ix', 'pred_19']], on='row_ix', how='left')\n",
    "    \n",
    "    # check the error\n",
    "    # ncc_gdf['error'] = ncc_gdf.apply(lambda x: x['pred18'] if x['pred18'] != x['code'] else x['pred19'], axis=1)\n",
    "    return ncc_gdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_map = '../../../results/RF/change_D/change_map_case_2.tif'\n",
    "gt_source = '../../../data/sample_shapefiles/samples_oso2018_T31TCJ.shp'\n",
    "gt_target = '../../../data/sample_shapefiles/samples_oso2019_T31TCJ.shp'\n",
    "pred_source = '../../../results/RF/2018_rf_model_2_map.tif'\n",
    "pred_target = '../../../results/RF/2019_rf_model_2_map.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 19.55838039716085 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "important_gdf = changeErrorCheck(change_map, gt_source, gt_target, pred_source, pred_target)\n",
    "print(\"Training time: %s minutes\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 1 = Run time: 19.66328562895457 minutes\n",
    "model 2 = Run time: 19.55838039716085 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errorstat = important_gdf.groupby(['pred_18', 'pred_19']).size()\n",
    "errorstat_df = errorstat.to_frame(name= 'count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorstat_df.sort_values(by=['count'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_18</th>\n",
       "      <th>pred_19</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>169403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>147284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>89918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_18  pred_19   count\n",
       "13       2.0      2.0  169403\n",
       "14       2.0      3.0  147284\n",
       "32       3.0      2.0   89918\n",
       "28       2.0     18.0   85780\n",
       "33       3.0      3.0   75513\n",
       "..       ...      ...     ...\n",
       "266     17.0     12.0       1\n",
       "183     12.0      7.0       1\n",
       "60       4.0     12.0       1\n",
       "238     16.0      1.0       1\n",
       "177     10.0     19.0       1\n",
       "\n",
       "[329 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorstat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorstat_df_with_ur = errorstat_df[errorstat_df['pred_18'] != errorstat_df['pred_19']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_18</th>\n",
       "      <th>pred_19</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>147284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>89918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>52926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_18  pred_19   count\n",
       "14       2.0      3.0  147284\n",
       "32       3.0      2.0   89918\n",
       "28       2.0     18.0   85780\n",
       "23       2.0     13.0   52926\n",
       "15       2.0      4.0   48113\n",
       "..       ...      ...     ...\n",
       "266     17.0     12.0       1\n",
       "183     12.0      7.0       1\n",
       "60       4.0     12.0       1\n",
       "238     16.0      1.0       1\n",
       "177     10.0     19.0       1\n",
       "\n",
       "[311 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorstat_df_with_ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "save_df = '../../../results/RF/change_D/errorstats'\n",
    "\n",
    "errorstat_df.to_csv(os.path.join(save_df, 'errorstat_df.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_gdf.to_file('checkerror_model_2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "if isinstance(errorstat_df, pd.DataFrame):\n",
    "    print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e38d1b7c6fa1584c154d3945271714c9a8c8ae23c3332553eb4d033ec2a2fa71"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
