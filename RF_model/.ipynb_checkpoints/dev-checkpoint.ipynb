{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# import os\n",
    "from utils.utils import load_npz, read_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 33\n",
    "n_channel = 10\n",
    "\n",
    "def standardize(X):\n",
    "    m = X.mean(axis=1)\n",
    "    s = X.std(axis=1)\n",
    "    X = (X - m) / s\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a .npz file\n",
    "    \"\"\"\n",
    "    with np.load(file_path) as data:\n",
    "        X = data[\"X\"]\n",
    "        y = data[\"y\"]\n",
    "        # polygon_ids = data[\"polygon_ids\"]\n",
    "        block_ids = data[\"block_id\"]\n",
    "    return X, y, block_ids#, polygon_ids\n",
    "\n",
    "######### Read Train, Validation, and Test ids #########\n",
    "\n",
    "def read_ids(file_path):\n",
    "    \"\"\"\n",
    "    Read ids from file\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        Train_ids = eval(lines[0].split(\":\")[1])\n",
    "        test_ids = eval(lines[1].split(\":\")[1])\n",
    "        # Eval_ids = eval(lines[2].split(\":\")[1])\n",
    "    return Train_ids, test_ids#, Eval_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SITSData(Dataset):\n",
    "    def __init__(self, case: int, source_sits, target_sits, train_val_eval, set= 'trainval', transform=None):\n",
    "        self.source_sits = source_sits\n",
    "        self.target_sits = target_sits\n",
    "        self.train_val_eval = train_val_eval\n",
    "        self.transform = transform\n",
    "        self.case = case\n",
    "        self.set = set\n",
    "        \n",
    "        # read the set ids\n",
    "        self.train_ids, self.test_ids = read_ids(self.train_val_eval)\n",
    "        \n",
    "        # case selection\n",
    "        if self.set == 'trainval':\n",
    "            ids = self.train_ids\n",
    "        elif self.set == 'test':\n",
    "            ids = self.test_ids\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a set between trainval and test\")\n",
    "\n",
    "        # read the data \n",
    "\n",
    "        X_source, y_source, block_ids_source = load_npz(self.source_sits)\n",
    "        X_target, y_target, block_ids_target = load_npz(self.target_sits)\n",
    "\n",
    "        _source = np.concatenate((X_source, y_source[:, None], block_ids_source[:, None]), axis=1)\n",
    "        _target = np.concatenate((X_target, y_target[:, None], block_ids_target[:, None]), axis=1)\n",
    "\n",
    "        _source = _source[np.isin(_source[:, -1], ids)]\n",
    "        _target = _target[np.isin(_target[:, -1], ids)]\n",
    "\n",
    "        self.Xtrain_source = _source[:, :-2]\n",
    "        self.ytrain_source = _source[:, -2]\n",
    "\n",
    "        self.Xtrain_target = _target[:, :-2]\n",
    "        self.ytrain_target = _target[:, -2]\n",
    "\n",
    "        if self.case == 1:\n",
    "            self.Xtrain = np.concatenate((self.Xtrain_source, self.Xtrain_target), axis=0)\n",
    "            self.ytrain = np.concatenate((self.ytrain_source, self.ytrain_target), axis=0)\n",
    "        elif self.case == 2:\n",
    "            self.Xtrain = self.Xtrain_source\n",
    "            self.ytrain = self.ytrain_source\n",
    "        elif self.case == 3:\n",
    "            self.Xtrain = self.Xtrain_target\n",
    "            self.ytrain = self.ytrain_target\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a case between 1 and 3\")      \n",
    "\n",
    "        print(\"The number of training samples is: \", self.Xtrain.shape[0])\n",
    "        print(\"The number of training samples is: \", self.ytrain.shape[0])  \n",
    "\n",
    "        def __len__(self):\n",
    "            return self.ytrain.shape[0]\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            X = self.Xtrain[idx]\n",
    "            y = self.ytrain[idx]\n",
    "            if self.transform:\n",
    "                X = self.transform(X)\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SITSData(Dataset):\n",
    "    def __init__(self, case: int, source_sits, target_sits, train_val_eval, set= 'trainval', transform=None):\n",
    "        self.source_sits = source_sits\n",
    "        self.target_sits = target_sits\n",
    "        self.train_val_eval = train_val_eval\n",
    "        self.transform = transform\n",
    "        self.case = case\n",
    "        self.set = set\n",
    "        \n",
    "        # read the set ids\n",
    "        self.train_ids, self.test_ids = read_ids(self.train_val_eval)\n",
    "        \n",
    "        # case selection\n",
    "        if self.set == 'trainval':\n",
    "            ids = self.train_ids\n",
    "        elif self.set == 'test':\n",
    "            ids = self.test_ids\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a set between trainval and test\")\n",
    "\n",
    "        # read the data \n",
    "\n",
    "        X_source, y_source, block_ids_source = load_npz(self.source_sits)\n",
    "        X_target, y_target, block_ids_target = load_npz(self.target_sits)\n",
    "\n",
    "        _source = np.concatenate((X_source, y_source[:, None], block_ids_source[:, None]), axis=1)\n",
    "        _target = np.concatenate((X_target, y_target[:, None], block_ids_target[:, None]), axis=1)\n",
    "\n",
    "        _source = _source[np.isin(_source[:, -1], ids)]\n",
    "        _target = _target[np.isin(_target[:, -1], ids)]\n",
    "\n",
    "        self.Xtrain_source = _source[:, :-2]\n",
    "        self.ytrain_source = _source[:, -2]\n",
    "\n",
    "        self.Xtrain_target = _target[:, :-2]\n",
    "        self.ytrain_target = _target[:, -2]\n",
    "\n",
    "        if self.case == 1:\n",
    "            self.Xtrain = np.concatenate((self.Xtrain_source, self.Xtrain_target), axis=0)\n",
    "            self.ytrain = np.concatenate((self.ytrain_source, self.ytrain_target), axis=0)\n",
    "        elif self.case == 2:\n",
    "            self.Xtrain = self.Xtrain_source\n",
    "            self.ytrain = self.ytrain_source\n",
    "        elif self.case == 3:\n",
    "            self.Xtrain = self.Xtrain_target\n",
    "            self.ytrain = self.ytrain_target\n",
    "        else:\n",
    "            raise ValueError(\"Please choose a case between 1 and 3\")      \n",
    "\n",
    "        print(\"The number of training samples is: \", self.Xtrain.shape[0])\n",
    "        print(\"The number of training samples is: \", self.ytrain.shape[0])  \n",
    "\n",
    "        def __len__(self):\n",
    "            return self.ytrain.shape[0]\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            X = self.Xtrain[idx]\n",
    "            y = self.ytrain[idx]\n",
    "            if self.transform:\n",
    "                X = self.transform(X)\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sits = \"../2018_SITS_data.npz\"\n",
    "target_sits = \"../2018_SITS_data.npz\"\n",
    "train_val_eval = \"../train_val_eval.txt\"\n",
    "case = 2\n",
    "set = \"trainval\"\n",
    "transform = None\n",
    "dataset = SITSData(case, source_sits, target_sits, train_val_eval, set, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.ones((100, 10), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../2018_SITS_data.npz\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# load npz file\n",
    "npz_2018 = np.load(path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e38d1b7c6fa1584c154d3945271714c9a8c8ae23c3332553eb4d033ec2a2fa71"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pycuda-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
